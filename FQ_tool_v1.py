import arcpy

from arcpy import env

import sqlite3

import random

import os

import sys

import xlsxwriter

from decimal import Decimal

import datetime as dt

import smtplib

import traceback

import string

from email.mime.text import MIMEText

from email.mime.multipart import MIMEMultipart

from email.mime.base import MIMEBase

from email.utils import COMMASPACE, formatdate

from email import encoders

from random import randint

import datetime

#import ctypes

import ConfigParser

import re

 

#CGF2

#MessageBox = ctypes.windll.user32.MessageBoxA

 

start_time = dt.datetime.now()

 

#---------------------------------------------------------------------------

# CRQ000000026545

# Added "Admin Flag" pipe column to Create_Pipe_FeatureClass() function,

# Load_Pipe_Data() function, and global pipe_col_aliases[] collection

#---------------------------------------------------------------------------

# 29NOV2016 -- CRQ000000032190, CRQ000000035499, CRQ000000043966

#---------------------------------------------------------------------------

# CRQ000000035499

# Added "MAOP Subsystem" pipe column to Create_Pipe_FeatureClass() function,

# Load_Pipe_Data() function, and global pipe_col_aliases[] collection

#---------------------------------------------------------------------------

# CRQ000000059380

# Added "Service Object SWGUID" pipe column to Create_Pipe_FeatureClass() function,

# Load_Pipe_Data() function, and global pipe_col_aliases[] collection

 

 

#Software version

version = "2.1.2"

 

#User's SDE and reports network file path

user_directory = ""

user_division = ""
#\\swgas.com\swgshr\gis\prod\SCA\Gas Facilities Quantities Toolbox Configurations
configuration_directory = ""

 

#User selectable columns fsor pipes_intersect and sqlite copy

pipe_col_aliases = ["Pipe Layer Name",

                    "Main or Service",

                    "Pipe Type",

                    "Material",

                    "M-Rec Complete",

                    "M-Rec Method (0-6)",

                    "Test Pressure",

                    "Size (Outside Diameter)",

                    "Wall Thickness",

                    "Grade",

                    "OpsSysName",

                    "System MOP",

                    "Inside Diameter",

                    "Install Year",

                    "Install Month",

                    "Manufacturer",

                    "FName",

                    "LName",

                    "PIMSysName",

                    "Job / WR Number",

                    "Joint Trench: Electric",

                    "Joint Trench: Telephone",

                    "Joint Trench: Water",

                    "Joint Trench: Sewer",

                    "Joint Trench: Gas",

                    "MAOP Determinant",

                    "Segment MAOP",

                    "System MAOP",

                    "SWG ID",

                    "Status",

                    "Admin Flag",

                    "MAOP Subsystem",

                    "Service Object SWGUID",

                    "XY Endpoint"]

 

#Default boundary layers, field names, and field aliases

boundary_defaults = []

boundary_field_defaults = []

boundary_alias_defaults = []

 

#Generated by Create_Pipe_FeatureClass()

pipe_intersect_fields = []

pipe_intersect_types = []

 

#Input from main and service table for Create_Pipe_FeatureClass()

pipe_source_fields = []

 

#Point fields

point_fields = []

point_source_fields = []

point_intersect_fields = []

 

#SQLite column definitions (copy of in_memory/pipes_intersect)

sqlite_fields = []

sqlite_types = []

sqlite_aliases = []

 

#Pipe types

pipe_types = ["Distribution","Feeder","High Pressure","Standard","Transmission","Transmission > 20"]

 

#Material names and IDs

material_names = ["AA","CU","HD","PE","ABS","MPE","PLS","PVC","STL","PE8100","GDB50","PE8300","PE8400"]

material_ids = [1,2,3,4,5,6,7,8,9,10,11,17,16]

 

#Global vars for custom implementation of "altered" property

in_boundary_lyr_lastval = ""

in_boundary_lyr_lastval_2 = ""

in_facility_lyrs_lastval = ""

 

#TBA, reset in execute() function start

error_list = []

 

class Toolbox(object):

    def __init__(self):

        global version

 

        self.label = "Gas Facilities Quantities Report " + version

        self.alias = "Gas Facilities Quantities Report " + version

 

        # List of tool classes associated with this toolbox

        self.tools = [Tool]

 

class Tool(object):

 

    #Parameter offsets for form fields

    #in_workspace = 0

    #CGF2

    in_retrieve_prefs = 0

   

    in_facility_layers = 1

 

    in_boundary_lyr = 2

    in_boundary_cols = 3

    in_boundary_alias_cols = 4

    in_boundary_filter = 5

 

    in_boundary_lyr_2 = 6

    in_boundary_cols_2 = 7

    in_boundary_alias_cols_2 = 8

    in_boundary_filter_2 = 9

 

    in_pipe_cols = 10

    in_point_cols = 11

 

    in_pipe_materials = 12

    in_pipe_types = 13

    in_size_from = 14

    in_size_to = 15

    in_date_from = 16

    in_date_to = 17

    in_year_list = 18

 

    #in_main_or_service = 17

    #in_riser_count = 17

    #in_premise_count = 18

 

    in_length_type = 19

   

    out_directory = 22

    out_file_name = 20

    out_save_as = 21

 

    #seconds elapsed

    def Time_Elapsed(self):

        global start_time

        return " (" + str((dt.datetime.now()-start_time).seconds) + " seconds elapsed)"

 

    def __init__(self):

        global version

        self.label = "Gas Facilities Quantities Report " + version

        self.description = "Gas Facilities Quantities Report " + version

        self.canRunInBackground = False

 

    #return list

    def List_Boundary_Layers(self, Do_Refresh = False):

        blist = []

 

        #if Do_Refresh == True:

        #    arcpy.RefreshTOC()

 

        mxd = arcpy.mapping.MapDocument("CURRENT")

        df = arcpy.mapping.ListDataFrames(mxd)[0]

        for lyr in arcpy.mapping.ListLayers(mxd, "", df):

 

            if lyr.supports("DATASOURCE"):

 

                try:

                    desc = arcpy.Describe(lyr)

 

                    if desc.shapeType == "Polygon" and \

                       str(lyr.name).find("Anno") == -1 and \

                       desc.shapeType == "Polygon" and \

                       desc.featureType == "Simple":

 

                        blist.append(lyr.name)

                except:

                    pass

 

        blist.sort()

        del mxd

 

        return blist

 

    def Load_Boundary_Defaults_File(self):

 

        global boundary_defaults

        global boundary_field_defaults

        global boundary_alias_defaults

        global configuration_directory

 

        boundary_defaults = []

        boundary_field_defaults = []

        boundary_alias_defaults = []

        file_lines = []

        linestr = ""

        cols = []

 

        #Try reading default_boundaries.txt

        try:

            f = open(configuration_directory + "default_boundaries.txt")

            file_lines = f.readlines()

        except:

            pass

 

        if len(file_lines) >= 2:

            for i in range(1, len(file_lines)):

                linestr = str(file_lines[i])

                linestr = linestr.replace("\n","")

                linestr = linestr.rstrip()

 

                cols = linestr.split("|")

 

                if len(cols) == 3:

                    boundary_defaults.append(str(cols[0]))

                    boundary_field_defaults.append(str(cols[1]))

                    boundary_alias_defaults.append(str(cols[2]))

 

    def Broadcast_Completion_Receipt(self, p, Excel_Path):

        global user_division

        ad_name = os.environ.get("USERNAME").upper()

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Sending completion receipt to " + ad_name + "@swgas.com" + self.Time_Elapsed())

        subject = "Quantities Toolbox: Completion Receipt (" + ad_name + ", " + user_division + ")"

 

        html = self.HTML_Header()

        html = html + self.Title_Row("Quantities Report: Completion Receipt")

        html = html + "<tr><td colspan='2'><b>Excel file location:</b><br>" + \

                      "<a href='" + user_directory + "'>" + Excel_Path + "</a><br></td></tr>"

       

        #Add data from user form

        html = html + self.Input_Summary_HTML(p)

        html = html + "</table></body></html>"

 

        if ad_name != "SXKM":

            self.Send_Email(html,subject,gisadmin@swgas.com)

 

        self.Send_Email(html,subject,os.environ.get("USERNAME").upper() + "@swgas.com")

 

    #Broadcast error message with form input parameters in HTML format

    def Broadcast_Errors_And_Exit(self, p, ErrorStr):

        global user_division

        arcpy.AddMessage("Error occured: " + ErrorStr)

        arcpy.AddMessage("Preparing error report email...")

 

        ad_name = os.environ.get("USERNAME").upper()

 

        subject = "Quantities Toolbox: Error Report (" + ad_name + ", " + user_division + ")"

 

        html = self.HTML_Header()

        html = html + self.Title_Row("Error Message")

        html = html + "<tr><td colspan='2'>" + ErrorStr + "</td></tr>"

 

        #Add data from user form

        html = html + self.Input_Summary_HTML(p)

        html = html + "</table></body></html>"

 

        if ad_name != "SXKM":

            self.Send_Email(html,subject,Craig.Ferris@swgas.com)

 

        self.Send_Email(html,subject,os.environ.get("USERNAME").upper() + "@swgas.com")

 

        arcpy.ClearWorkspaceCache_management()

        arcpy.Delete_management("in_memory")

 

        raise Exception(ErrorStr)

 

    def Title_Row(self,title):

        html = "<tr><td colspan='2' bgcolor='#666666' style='font-color:#ffffff;font-size:13px;'>"

        html = html + "<font color='#ffffff'><b>" + title + "</b></font></td></tr>"

 

        return html

 

    def Send_Email(self, html, subject, addr):

        msg = MIMEMultipart("alternative")

        msg["Subject"] = subject

        msg["From"] = addr

        msg["To"] = addr

 

        msg.attach(MIMEText("Please use an HTML-capable email client.","plain"))

        msg.attach(MIMEText(html,"html"))

 

        #Broadcast email

        s = smtplib.SMTP("smtp.swgas.com")

        s.sendmail(msg["From"], msg["To"], msg.as_string())

        s.quit()

 

    #Create html summary of user input

    def Input_Summary_HTML(self, p):

        html = self.Title_Row("Form Input Summary")

 

        for i in range(0, len(p)):

            bg = "#ffffff"

            if i%2 == 0:

                bg = "#eeeeee"

 

            html = html + "<tr><td bgcolor='" + bg + "' width='50%' valign='top'><b>" + str(p[i].name) + ":</b></td>"

            html = html + "<td bgcolor='" + bg + "' width='50%' valign='top'>" + str(p[i].value).replace("'","") + "</td></tr>"

 

        return html

 

    #Create html headers for email receipts

    def HTML_Header(self):

        html = "<html><body leftmargin='0' topmargin='0' rightmargin='0'>"

        html = html + "<table style='font-family:arial;font-size:11px;border-width:1px;border-style:solid;border-color:#cccccc;border-collapse:collapse;' "

        html = html + "width='100%' cellpadding='2' cellspacing='0' border='1' bordercolor='#cccccc'>"

 

        return html

 

    def Get_Root_Directory(self):

        ret = ""

       

        try:

            fr = None

            fr = open(os.path.dirname(os.path.realpath(__file__)) + \\path.config.txt, 'r')

            ls = fr.readlines()

            fr.close()

            ret = str(ls[0])

        except Exception, e:

            raise Exception(str(e))

        finally:

            if fr:

                fr = None

 

        return ret

 

    #Determine user's access level by checking division shared folder access

    def Division_FilePath(self):

        global user_directory

        global user_division

        global configuration_directory

       

        count = 0

        #root = \\\\swgas.com\\swgshr\\gisshr\\GIS\\

        root = self.Get_Root_Directory()

       

        dv = ["CORP","SAZ","CAZ","NNV","SNV","SCA","GB"]

        content_list = []

 

        for i in range(0, len(dv)):

 

            #Check if directory exists

            if os.path.exists(root + dv[i]) == True:

 

                #Check if contents can be listed

                content_list = []

                try:

                    content_list = os.listdir(root + dv[i])

                except:

                    pass

 

                #Contents listed

                if len(content_list) >= 1:

 

                    #Check for write and execute access

                    if os.access(root + dv[i], os.W_OK) == True and \

                       os.access(root + dv[i], os.X_OK) == True:

 

                        user_division = dv[i]

                        user_directory = root + dv[i] + \\Reports\\

                        configuration_directory = root + dv[i] + \\Gas Facilities Quantities Toolbox Configurations\\

                        break

 

        if user_division == "":

            raise Exception("Toolbox authentication failed.")

 

    #Define user interface fields

    def getParameterInfo(self):

 

        global mts

        global pipe_col_aliases

        global pipe_types

 

        #Determine which division the user is in

        self.Division_FilePath()

 

        #Load boundary name and alias defaults

        #self.Load_Boundary_Defaults_File()

 

        global user_directory

 

        selected_msg = " (if features were selected, only selected features will be processed)"

        pipes_only_msg = " (applicable to pipe layers only)"

 

        #CGF2

        #Retrieve Report Input Parameters File input

        p_retrieve_prefs = arcpy.Parameter(

        name="QTF", displayName="Retrieve Report Input Parameters: Query Text File",

        datatype="DEFile", parameterType="Optional", direction="Input")

        p_retrieve_prefs.filter.list = ["cfg"]

        ##self._settings = configuration_directory

        ##p_retrieve_prefs.value = configuration_directory

 

        # 1 or more pipe layers from TOC

        p_pipe_layers = arcpy.Parameter(

        name="MSP", displayName="Main, Service, or Point Layer(s)" + selected_msg,

        datatype="GPLayer", parameterType="Required", direction="Input",

        multiValue="True")

 

        p_pipe_layers.values = ["GasFacilities/Main", "GasFacilities/Service"]

 

        boundary_list = self.List_Boundary_Layers()

       

        #PRIMARY Boundary layer selection

        p_boundaries = arcpy.Parameter(

        name="PB_TOC", displayName="Primary Boundary Layer from ArcMap Table of Contents" + selected_msg,

        datatype="GPString", parameterType="Required", direction="Input")

        p_boundaries.filter.type = "ValueList"

        p_boundaries.filter.list = boundary_list

        p_boundaries.value="District"

 

        #PRIMARY Boundary Text File input

        p_boundary_filter = arcpy.Parameter(

        name="PB_TXT", displayName="Primary Boundary Layer: Query Text File",

        datatype="DEFile", parameterType="Optional", direction="Input")

        p_boundary_filter.filter.list = ["txt"]

 

        #PRIMARY Boundary columns

        p_boundary_cols = arcpy.Parameter(

        name="PB_COL", displayName="Primary Boundary Layer: List of fields for report, comma delimited",

        datatype="GPString", parameterType="Required", direction="Input")

        p_boundary_cols.value = "BOUNDARYNAMEID"

 

        #PRIMARY Boundary aliases

        p_boundary_aliases = arcpy.Parameter(

        name="PB_ALIAS", displayName="Primary Boundary Layer: List of field aliases for report header, comma delimited",

        datatype="GPString", parameterType="Required", direction="Input")

        p_boundary_aliases.value = "Boundary Name"

 

        #--------------------------------------------------------------------------------------

        #SECONDARY Boundary layer selection

        p2_boundaries = arcpy.Parameter(

        name="SB_TOC", displayName="Secondary Boundary Layer from ArcMap Table of Contents" + selected_msg,

        datatype="GPString", parameterType="Optional", direction="Input")

 

        p2_boundaries.filter.type = "ValueList"

        p2_boundaries.filter.list = boundary_list

 

        #SECONDARY Boundary Text File input

        p2_boundary_filter = arcpy.Parameter(

        name="SB_TXT", displayName="Secondary Boundary Layer: Query Text File",

        datatype="DEFile", parameterType="Optional", direction="Input")

        p2_boundary_filter.filter.list = ["txt"]

 

        #SECONDARY Boundary columns

        p2_boundary_cols = arcpy.Parameter(

        name="SB_COL", displayName="Secondary Boundary Layer: List of fields for report, comma delimited",

        datatype="GPString", parameterType="Optional", direction="Input")

        p2_boundary_cols.value = "BOUNDARYNAMEID"

 

        #SECONDARY Boundary aliases

        p2_boundary_aliases = arcpy.Parameter(

        name="SB_ALIAS", displayName="Secondary Boundary Layer: List of field aliases for report header, comma delimited",

        datatype="GPString", parameterType="Optional", direction="Input")

        p2_boundary_aliases.value = "Boundary Name"

 

        #Pipe Column selection

        p_ouput_cols = arcpy.Parameter(

        name="MS_RPT", displayName="Main/Service column(s) for report (Division, Main Length, Service Length, and Total Length are included by default)",

        datatype="GPString",

        parameterType="Required",

        direction="Input",

        multiValue="True")

 

        p_ouput_cols.filter.type = "ValueList"

        p_ouput_cols.filter.list = pipe_col_aliases

 

        #Set default selected values

        p_ouput_cols.values = [pipe_col_aliases[0],pipe_col_aliases[1],pipe_col_aliases[2],pipe_col_aliases[3],pipe_col_aliases[4],pipe_col_aliases[5],pipe_col_aliases[6]

                                ,pipe_col_aliases[7],pipe_col_aliases[8],pipe_col_aliases[9],pipe_col_aliases[10],pipe_col_aliases[11]]

 

        #Point column selection

        p_point_cols = arcpy.Parameter(

        name="PT_COL_RPT", displayName="Point column(s) for report (Division, Count, and Layer Name are included by default)",

        datatype="GPString",

        parameterType="Optional",

        direction="Input",

        multiValue="True")

 

        p_point_cols.filter.type = "ValueList"

 

        #Debug for now

        #p_ouput_cols.values = pipe_col_aliases

 

        #Material selection

        p_materials = arcpy.Parameter(

        name="MATERIAL", displayName="Material" + pipes_only_msg,

        datatype="GPString",

        parameterType="Required",

        direction="Input",

        multiValue="True")

 

        p_materials.filter.type = "ValueList"

        p_materials.filter.list = material_names

        p_materials.values = material_names

 

        #Pipe type selection, such as Transmission

        p_pipe_types = arcpy.Parameter(

        name="TYPE", displayName="Type" + pipes_only_msg,

        datatype="GPString",

        parameterType="Required",

        direction="Input",

        multiValue="True")

 

        p_pipe_types.filter.type = "ValueList"

        p_pipe_types.filter.list = pipe_types

        p_pipe_types.values = pipe_types

 

        p_test = arcpy.Parameter(

        name="DEBUG", displayName="Debug",

        datatype="GPString",

        parameterType="Optional",

        direction="Input")

 

        p_diameter_from = arcpy.Parameter(

        name="SZ_RNG_MIN", displayName="Size Range: Minimum" + pipes_only_msg,

        datatype="GPDouble",

        parameterType="Optional",

        direction="Input")

 

        p_diameter_to = arcpy.Parameter(

        name="SZ_RNG_MAX", displayName="Size Range: Maximum" + pipes_only_msg,

        datatype="GPDouble",

        parameterType="Optional",

        direction="Input")

 

        #Install Date Range

        p_install_date_from = arcpy.Parameter(

        name="INSTALL_DT_RNG_MIN", displayName="Install Date Range: Minimum",

        datatype="GPDate",

        parameterType="Optional",

        direction="Input")

 

        p_install_date_to = arcpy.Parameter(

        name="INSTALL_DT_RNG_MAX", displayName="Install Date Range: Maximum",

        datatype="GPDate",

        parameterType="Optional",

        direction="Input")

 

        #Install Year list

        p_install_year_list = arcpy.Parameter(

        name="INSTALL_YRS", displayName="List of Install Years, Comma Delimited",

        datatype="GPString",

        parameterType="Optional",

        direction="Input")

 

        #Recorded length or shape length

        p_length_type = arcpy.Parameter(

        name="CALC_PIPE", displayName="Calculate Pipe Recorded Length or Shape Length",

        datatype="GPString", parameterType="Required", direction="Input")

        p_length_type.filter.type = "ValueList"

        p_length_type.filter.list = ["Recorded Length","Shape Length"]

        p_length_type.value = "Recorded Length"

 

        #Output folder

        p_output_directory = arcpy.Parameter(

        displayName="Output Directory", name="",

        datatype="DEFolder",

        parameterType="Required",

        direction="Input")

 

        #DEFolder

        p_output_directory.value = user_directory

        p_output_directory.enabled = True

 

        #User Preferences File Name

        p_user_preferences_file_name = arcpy.Parameter(

        name="USER_PREF_FILE", displayName="User Preferences File Name",

        datatype="GPString",

        parameterType="Optional",

        direction="Input")

       

        #CGF2

        #Save As... (User Preferences)

        p_save_as = arcpy.Parameter(

        name="SAVE", displayName="Check to Save Report Preferences...",

        datatype="Boolean",

        parameterType="Optional",

        direction="Input")

       

        #CGF2

##        params = [p_retrieve_prefs, p_pipe_layers, p_boundaries, p_boundary_cols, p_boundary_aliases,

##                  p_boundary_filter, p2_boundaries, p2_boundary_cols, p2_boundary_aliases, p2_boundary_filter,

##                  p_ouput_cols, p_point_cols, p_materials, p_pipe_types, p_diameter_from, p_diameter_to,

##                  p_install_date_from, p_install_date_to, p_install_year_list, p_length_type, p_output_directory,

##                  p_user_preferences_file_name, p_save_as]

 

        params = [p_retrieve_prefs, p_pipe_layers, p_boundaries, p_boundary_cols, p_boundary_aliases,

            p_boundary_filter, p2_boundaries, p2_boundary_cols, p2_boundary_aliases, p2_boundary_filter,

            p_ouput_cols, p_point_cols, p_materials, p_pipe_types, p_diameter_from, p_diameter_to,

            p_install_date_from, p_install_date_to, p_install_year_list, p_length_type,

            p_user_preferences_file_name, p_save_as]

 

        for i in range(0, len(params)):

            params[i].name = params[i].displayName

 

        return params

 

    def isLicensed(self):

        """Set whether tool is licensed to execute."""

        return True

 

    ##Python Toolbox template method.  Don't do anything here.

    ##Let updateMessages handle custom validation after internal arcpy validation

    def updateParameters(self, parameters):

        return

 

    def fieldExists(self, featureclass, fieldname):

        fieldList = arcpy.ListFields(featureclass, fieldname)

        fieldCount = len(fieldList)

        if (fieldCount == 1):

            return True

        else:

            return False

 

    #CGF2

    #Validate text file filter for boundary layer

    def validate_RetrievePrefs(self, p):

        has_error = False

       

        in_retrieve_prefs = p[self.in_retrieve_prefs]

           

        if has_error == False:

            in_retrieve_prefs.clearMessage()

 

        file_name = str(in_retrieve_prefs.value).strip()

        in_retrieve_prefs.value = ''

        #MessageBox(None, file_name, 'validate_RetrievePrefs', 0)

        if os.path.isfile(file_name):

            self.load_settings(p, file_name)

            self.updateMessages(p)

            self.load_settings(p,file_name)

           

            return True

        else:

            return False

       

            

    def validate_BoundaryLayer(self, p, primary_secondary = "primary"):

        global user_division

 

        ##CGF2 Test

        #MessageBox(None, 'validate_BoundaryLayer', 'validate_BoundaryLayer', 0)

       

        standard_lyr_found = False

 

        if primary_secondary == "primary":

            in_boundary_lyr = p[self.in_boundary_lyr]

            in_boundary_cols = p[self.in_boundary_cols]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols]

        else:

            in_boundary_lyr = p[self.in_boundary_lyr_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols_2]

 

        secondary_lyr = p[self.in_boundary_lyr_2]

        primary_lyr = p[self.in_boundary_lyr]

 

        if in_boundary_lyr.value != None and in_boundary_lyr.hasError() == False:

 

            layername = str(in_boundary_lyr.value).upper()

            desc = arcpy.Describe(in_boundary_lyr.value)

 

            #Check if boundary layer is Simple Polygon type

            if desc.shapeType != "Polygon":

                in_boundary_lyr.setErrorMessage("Primary boundary layer shape type must be Polygon")

            if desc.featureType != "Simple":

                in_boundary_lyr.setErrorMessage("Primary boundary layer feature type must be Simple, not " + desc.featureType)

  

            #Populate default boundary column mappings and aliases

            if in_boundary_lyr.hasError() == False and len(layername) >= 1:

 

                #SAZ_Layers = ["DISTRICT","OLDDOCBOUNDARY","BUSINESSDISTRICT","CLASSLOCATION","CP","ISOLATION AREA","LEAKSURVEY","TILEGRID"]

                #SAZ_Aliases = ["District","Old Doc Boundary","Business District","Class Location","Cathodic Protection","Isolation Area","Leak Survey","Grid Name"]

 

                in_boundary_alias_cols.value = "Boundary Name"

                in_boundary_cols.value = "BOUNDARYNAMEID"

 

                #Load boundary default text file

                self.Load_Boundary_Defaults_File()

                global boundary_defaults

                global boundary_alias_defaults

                global boundary_field_defaults

 

                for i in range(0, len(boundary_defaults)):

                    if layername == boundary_defaults[i]:

 

                        in_boundary_alias_cols.value = boundary_alias_defaults[i]

                        in_boundary_cols.value = boundary_field_defaults[i]

                        break

 

 

    def validate_BoundaryColumns(self, p, primary_secondary = "primary"):

       

        if primary_secondary == "primary":

            in_boundary_lyr = p[self.in_boundary_lyr]

            in_boundary_cols = p[self.in_boundary_cols]

        else:

            in_boundary_lyr = p[self.in_boundary_lyr_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

 

        column_match_passed = False

 

        #Single column case

        col_list = str(in_boundary_cols.value).split(",")

        for i in range(0, len(col_list)):

       

            #Column name entry is blank

            if col_list[i] == "":

 

                in_boundary_cols.setErrorMessage("Column name(s) entered must be not blank")

                break

           

            #Column name entry does not match boundary field

            elif col_list[i] != "" and \

                 self.fieldExists(str(in_boundary_lyr.value), col_list[i]) == False:

 

                in_boundary_cols.setErrorMessage("Column name(s) must match field names in boundary feature class")

                break

 

            else:

                column_match_passed = True

 

        #Check for shape column and objectid column

        if column_match_passed == True:

            if str(in_boundary_cols.value).find("SHAPE") >= 0 or \

               str(in_boundary_cols.value).find("OBJECTID") >= 0:

 

                in_boundary_cols.setErrorMessage("SHAPE or OBJECTID column entries are not permitted")

 

 

    def validate_BoundaryAliasColumns(self, p, primary_secondary = "primary"):

 

        if primary_secondary == "primary":

            in_boundary_cols = p[self.in_boundary_cols]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols]

        else:

            in_boundary_cols = p[self.in_boundary_cols_2]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols_2]

 

        col_names = str(in_boundary_cols.value).split(",")

        col_aliases = str(in_boundary_alias_cols.value).split(",")

        listsize_pass = True

 

        #Check if list sizes match

        if len(col_names) != len(col_aliases):

            in_boundary_alias_cols.setErrorMessage("Size of boundary field alias list must match size of boundary column list above")

            listsize_pass = False

 

        #Check if user entered a blank alias

        if listsize_pass == True:

 

            for i in range(0, len(col_aliases)):

                if col_aliases[i] == "":

                    in_boundary_alias_cols.setErrorMessage("Boundary field alias entries cannot be blank")

                    break

 

   

    #Validate text file filter for boundary layer

    def validate_BoundaryFilter(self, p, primary_secondary = "primary"):

 

        if primary_secondary == "primary":

            in_boundary_filter = p[self.in_boundary_filter]

            in_boundary_lyr = p[self.in_boundary_lyr]

            in_boundary_cols = p[self.in_boundary_cols]

        else:

            in_boundary_filter = p[self.in_boundary_filter_2]

            in_boundary_lyr = p[self.in_boundary_lyr_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

 

        has_error = False

 

        if in_boundary_filter.value != None:

 

            #Open text file and read all lines

            lines = open(str(in_boundary_filter.value), 'r').readlines()

 

            #Check if there is no data

            if len(lines) == 0:

                has_error = True

                in_boundary_filter.setErrorMessage("Boundary filter text file contains no data")

 

            elif len(lines) == 1:

                has_error = True

                in_boundary_filter.setErrorMessage("Boundary filter text file contains header, but no data")

 

            #Check if number of columns in all rows are the same

            if in_boundary_filter.hasError() == False:

                headercount = len(lines[0].split("|"))

 

                for i in range(1,len(lines)):

                    if lines[i] != "":

                        tempcount = len(lines[i].split("|"))

                        if tempcount != headercount:

                            has_error = True

                            in_boundary_filter.setErrorMessage("All boundary filter file lines must have the same number of columns")

                            break

 

            #Validate file header against boundary feature class field names

            if in_boundary_filter.hasError() == False:

 

                headercols = lines[0].split("|")

                for d in range(0, len(headercols)):

                    headercols[d] = headercols[d].replace("\n","")

 

                    if self.fieldExists(str(in_boundary_lyr.value), headercols[d]) == False:

                        has_error = True

                        in_boundary_filter.setErrorMessage("1 or more header column names do not match field names in boundary layer")

                        break

 

            #Validate file header against user-entered comma-delimited boundary field names

            if in_boundary_filter.hasError() == False and in_boundary_cols.value != None:

 

                headercols = lines[0].split("|")

                for d in range(0, len(headercols)):

                    headercols[d] = headercols[d].replace("\n","")

 

                    if str(in_boundary_cols.value).find(headercols[d]) == -1:

                        in_boundary_filter.setErrorMessage("1 or more header column names do not match list of boundary columns for report")

                        break

 

        if has_error == False:

            in_boundary_filter.clearMessage()

 

 

    def validate_SizeRange(self, p):

 

        in_size_from = p[self.in_size_from]

        in_size_to = p[self.in_size_to]

        has_error = False

        size_from = 0

        size_to = 0

 

        if in_size_from.value != None:

            size_from = float(in_size_from.value)

        if in_size_to.value != None:

            size_to = float(in_size_to.value)

 

        #Max size is less than min size

        if size_to < size_from and in_size_from.value != None:

            in_size_to.setErrorMessage("Maximum pipe size must be greater or equal to minimum size")

            has_error = True

 

        #Min size is more than max size

        elif size_from > size_to and in_size_to.value != None:

            in_size_from.setErrorMessage("Minimum pipe size must be less or equal to maximum size")

            has_error = True

 

        #Check for negative values

        if has_error == False:

            if size_from < 0:

                in_size_from.setErrorMessage("Minimum pipe size cannot be a negative number")

                has_error = True

            if size_to < 0:

                in_size_to.setErrorMessage("Maximum pipe size cannot be a negative number")

                has_error = True

 

        if has_error == False:

            in_size_from.clearMessage()

            in_size_to.clearMessage()

 

    def validate_DateRange(self, p):

        in_date_from = p[self.in_date_from]

        in_date_to = p[self.in_date_to]

        format_error = "Date input must be in MM/DD/YYYY format"

 

        #in_debug = p[self.in_debug]

 

        #1899-12-30 08:49:48

        #2013-11-19 00:00:00

 

        #Validate date range

        if in_date_from.value != None or in_date_to.value != None:

 

            #in_debug.value = "'" + str(in_date_from.value) + "','" + str(in_date_to.value) + "'"

 

            from_str = str(in_date_from.value)

            to_str = str(in_date_to.value)

            date_from = None

            date_to = None

 

            in_date_from.clearMessage()

            in_date_to.clearMessage()

 

            try:

                if date_from != None:

                    date_from = datetime.datetime.strptime(from_str, '%Y-%m-%d %H:%M:%S')

            except:

                in_date_from.setErrorMessage(format_error)

                pass

 

            try:

                if date_to != None:

                    date_to = datetime.datetime.strptime(to_str, '%Y-%m-%d %H:%M:%S')

            except:

                in_date_to.setErrorMessage(format_error)

                pass

 

            #if len(to_str) > 12:

            #    in_date_to.setErrorMessage(format_error)

 

            #in_debug.value = "'" + str(date_from) + "','" + str(date_to) + "', " + str((date_from - date_to).total_seconds()) + ", " + str(random.randint(0,10000))

 

            if date_from != None and \

               date_to != None and \

              (date_from - date_to).total_seconds() >= 1.0:

 

                in_date_from.setErrorMessage("Date range minimum entry must be earlier than date range maximum entry")

 

    def validate_YearList(self, p):

        in_year_list = p[self.in_year_list]

        has_error = False

       

        if in_year_list.value != None:

            year_list = str(in_year_list.value).split(",")

 

            for i in range(0,len(year_list)):

                #check if year is not an integer

                if year_list[i].replace("-","").isdigit() == False:

                    in_year_list.setErrorMessage("1 or more entries in year list is blank or not a number")

                    has_error = True

                    break

 

                else:

                    if int(year_list[i]) < 0:

                        in_year_list.setErrorMessage("Year list entry cannot be a negative number");

                        has_error = True

                        break

 

        if has_error == False:

            in_year_list.clearMessage()

 

    def validate_OutputDirectory(self, p):

        out_directory = p[self.out_directory]

        validated = False

 

        if out_directory.value != None:

 

            lastchar = str(out_directory.value)[-1:]

            if lastchar == "\\" or lastchar == "/":

                validated = True

 

            if validated == False:

                out_directory.setErrorMessage("Last character of output directory must be a forward or black slash")

            else:

                out_directory.clearMessage()

 

 

    #CGF2

    #Validate text file filter for boundary layer

    def validate_OutSaveAs(self, p):

        has_error = False

       

        out_file_name = p[self.out_file_name]

        out_save_as = p[self.out_save_as]

 

        #MessageBox(None, 'out_directory: ' + configuration_directory, 'validate_OutSaveAs', 0)

        #MessageBox(None, 'out_file_name: ' + str(out_file_name.value), 'validate_OutSaveAs', 0)

        #MessageBox(None, 'out_save_as: ' + str(out_save_as.value), 'validate_OutSaveAs', 0)

           

        if has_error == False:

            out_save_as.clearMessage()

 

        if ((out_save_as.value == True) and (len(str(out_file_name.value).strip()) > 0) and (len(configuration_directory.strip()) > 0)):

            #MessageBox(None, 'Should not be here', 'validate_OutSaveAs', 0)

            file_name_save = str(out_file_name.value)

            config_file_save = os.path.join(configuration_directory, str(out_file_name.value))

  

##            try:

##                my_guess = os.path.join(configuration_directory, str(out_file_name.value), '.cfg')

##            except Exception as e:

##                MessageBox(None, e.message, 'validate_OutSaveAs', 0)

 

            self.save_settings(p, config_file_save)

##          MessageBox(None, 'SAVED', 'validate_OutSaveAs', 0)

 

       

    #Add/Remove point fields from point field selector

    def Refresh_Point_Fields(self, p):

      

        in_facility_layers = str(p[self.in_facility_layers].value).split(";")

        in_facility_layers_str = str(p[self.in_facility_layers].value)

        in_point_cols = p[self.in_point_cols]

 

        layer_fields_collection = []

        all_fields = []

        common_fields = []

        count = 0

        xy_fieldname = "XY COORDINATES"

 

        if len(in_facility_layers) >= 1:

 

            for i in range(0, len(in_facility_layers)):

 

                if in_facility_layers[i] != "None":

 

                    temp_str = str(in_facility_layers[i])

                    temp_str = temp_str.rstrip()

                    if len(temp_str) >= 1:

 

                        shape_str = self.Get_ShapeType(temp_str)

                        if shape_str == "Point":

 

                            fields = self.Get_FieldNames(temp_str, ["SHAPE","OBJECTID","SWGUID"])

                            fields.append("SWG_ID")

 

                            if len(fields) == 0:

                                layer_fields_collection = []

                                break

 

                            else:

                                count = count + 1

 

                                #Replace installation date with install year

                                for d in range(0, len(fields)):

                                    if fields[d] == "INSTALLATIONDATE":

                                        fields[d] = "INSTALL_YEAR"

                                        break

 

                                fields.sort()

                                all_fields.extend(list(fields))

                                layer_fields_collection.append(list(fields))

 

            #If there is 2 or more point layers, search for shared column names

            if count >= 2:

 

                temp_list = list(layer_fields_collection[0])

                temp_count = 0

 

                for i in range(0, len(temp_list)):

 

                    col_name = str(temp_list[i])

                    temp_count = 0

 

                    for d in range(0, len(all_fields)):

                        if all_fields[d] == col_name:

 

                            temp_count = temp_count + 1

                            if temp_count >= count:

                                common_fields.append(str(col_name))

                                break

 

                common_fields.append(xy_fieldname)

                common_fields.sort()

 

                in_point_cols.filter.list = list(common_fields)

                in_point_cols.value = ""

 

            elif count == 1:

 

                temp_list = list(layer_fields_collection[0])

 

                #If the layer is riser add Premise ID

                if in_facility_layers_str.find("Riser") >= 0:

                    temp_list.append("PREMISE ID")

                    temp_list.append("SAP PREMISE ID")

                   

 

                temp_list.append(xy_fieldname)              

                temp_list.sort()

 

                in_point_cols.filter.list = list(temp_list)

                in_point_cols.value = ""

 

        #No point layers found

        if count == 0:

            in_point_cols.filter.list = []

            in_point_cols.value = ""

       

    def updateMessages(self, p):

        global in_boundary_lyr_lastval

        global in_boundary_lyr_lastval_2

        global in_facility_lyrs_lastval

 

        #MessageBox(None, 'executing 0', 'updateMessages', 0)

               

        #CGF2 TODO

        in_retrieve_prefs = p[self.in_retrieve_prefs]

        ##CGF retrieve_prefs_file = str(in_retrieve_prefs.value).strip()

        out_file_name = p[self.out_file_name]

        out_save_as = p[self.out_save_as]

        ##CGF config_folder = str(out_directory.value).strip()

        ##CGF config_file = str(out_file_name.value).strip()

        ##CGF config_save = str(out_save_as.value).strip()

       

        in_boundary_lyr = p[self.in_boundary_lyr]

        in_boundary_cols = p[self.in_boundary_cols]

        in_boundary_alias_cols = p[self.in_boundary_alias_cols]

        in_boundary_filter = p[self.in_boundary_filter]

 

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        in_boundary_cols_2 = p[self.in_boundary_cols_2]

        in_boundary_alias_cols_2 = p[self.in_boundary_alias_cols_2]

        in_boundary_filter_2 = p[self.in_boundary_filter_2]

 

        in_facility_layers = p[self.in_facility_layers]

        in_point_cols = p[self.in_point_cols]

 

        in_size_from = p[self.in_size_from]

        in_size_to = p[self.in_size_to]

 

        in_date_from = p[self.in_date_from]

        in_date_to = p[self.in_date_to]

        in_year_list = p[self.in_year_list]

        in_pipe_cols = p[self.in_pipe_cols]

        #in_debug = p[self.in_debug]

 

        lyr_str = str(in_boundary_lyr.value)

        lyr_str_2 = str(in_boundary_lyr_2.value)

 

        #-------------------------------------------------------------------

        #CGF2

        #Validate Report Input Parameters File

        ##MessageBox(None, str(in_retrieve_prefs.value), 'in_retrieve_prefs', 0)

        if in_retrieve_prefs.value != None and \

            in_retrieve_prefs.altered == True and \

            in_retrieve_prefs.hasError() == False and \

            in_retrieve_prefs != "":

 

            self.validate_RetrievePrefs(p)

 

        ##MessageBox(None, str(out_file_name.value), 'out_file_name', 0)

        ##MessageBox(None, str(out_save_as.value), 'out_save_as', 0)

       

        ##MessageBox(None, str(out_file_name.value == None), 'out_file_name.value', 0)

        ##MessageBox(None, str(out_file_name.altered == True), 'out_file_name.altered == True', 0)

        ##MessageBox(None, str(out_file_name.hasError() == False), 'out_file_name.hasError()', 0)

        ##MessageBox(None, str(out_file_name != ""), 'out_file_name != ""', 0)

        ##MessageBox(None, str(out_save_as.value == True), 'out_save_as.value == True', 0)

       

        #Save Report Parameters Config File

        if out_file_name.value != None and \

            out_file_name.altered == True and \

            out_file_name.hasError() == False and \

            len(str(out_file_name.value).strip()) > 0:

       

            ##Remove any wildcards

            #MessageBox(None, 'About to fix name', 'updateMessages', 0)

            ##Remove wildcards but leave spaces

            config_file = re.sub('[^a-zA-Z0-9 \n\.]', '', str(out_file_name.value).strip())

            out_file_name.value = config_file

           

            if out_save_as.value == True:

                #MessageBox(None, 'About to Save', 'updateMessages', 0)

                #MessageBox(None, str(len(config_file.strip())), 'updateMessages', 0)

                #MessageBox(None, config_file.strip().upper()[-4:],'updateMessages', 0)

                ##If the user did not add an extension to the name, do it now

                if (len(config_file.strip()) > 1) and \

                    (config_file.strip().upper()[-4:] != '.CFG'):

                    config_file = config_file + '.cfg'

                out_file_name.value = config_file

                self.validate_OutSaveAs(p)

                #MessageBox(None, 'SAVED' +  + '!!!!', 'updateMessages', 0)

                out_save_as.value == False

       

        #PRIMARY boundary fields validation

 

        #Refresh PRIMARY boundary layers dropdown

        #if in_boundary_lyr.value == None:

        #    in_boundary_lyr.filter.list = self.List_Boundary_Layers(True)

 

        #Validate PRIMARY boundary layer input

        if in_boundary_lyr_lastval != str(in_boundary_lyr.value) and \

           in_boundary_lyr.hasError() == False and \

           lyr_str != "":

         

            in_boundary_lyr_lastval = str(in_boundary_lyr.value)

            self.validate_BoundaryLayer(p)

        #MessageBox(None, '5', 'updateMessages', 0)

        #Validate PRIMARY boundary column list input

        if (in_boundary_cols.altered == True or in_boundary_alias_cols.altered == True) and \

            in_boundary_cols.hasError() == False and \

            in_boundary_lyr.hasError() == False and \

            lyr_str != "":

 

            self.validate_BoundaryColumns(p)

            #MessageBox(None,in_boundary_lyr.value,"test",0)

        #MessageBox(None, '6', 'updateMessages', 0)

        #Validate PRIMARY boundary column alias list input

        if (in_boundary_lyr.altered == True or in_boundary_cols.altered == True or in_boundary_alias_cols.altered == True) and \

            in_boundary_alias_cols.hasError() == False:

 

            self.validate_BoundaryAliasColumns(p)

        #MessageBox(None, '7', 'updateMessages', 0)

        #Validate PRIMARY text file filter input

        if (in_boundary_filter.altered == True or in_boundary_cols.altered == True) and \

            in_boundary_filter.hasError() == False and \

            in_boundary_lyr.hasError() == False and \

            lyr_str != "":

 

            self.validate_BoundaryFilter(p)

        #MessageBox(None, '8', 'updateMessages', 0)

        #Referesh list of point layer fields

        if (str(in_facility_layers.value) != in_facility_lyrs_lastval or \

            in_facility_lyrs_lastval == "" or \

            in_facility_lyrs_lastval == None):

            #if ((in_facility_layers.value) == None):

                #MessageBox(None, '9', 'updateMessages', 1)

            #else:

            in_facility_lyrs_lastval = str(in_facility_layers.value)

            self.Refresh_Point_Fields(p)

        #MessageBox(None, '9', 'updateMessages', 0)

        #-------------------------------------------------------------------

        #SECONDARY boundary fields validation

 

        #Refresh SECONDARY boundary layers dropdown

        #if in_boundary_lyr_2.value == None:

        #    in_boundary_lyr_2.filter.list = self.List_Boundary_Layers(True)

 

        #Validate SECONDARY boundary layer input

        if in_boundary_lyr_2.value != None and \

           in_boundary_lyr_lastval_2 != str(in_boundary_lyr_2.value) and \

           in_boundary_lyr_2.hasError() == False and \

           lyr_str_2 != "":

 

            in_boundary_lyr_lastval_2 = str(in_boundary_lyr_2.value)

            self.validate_BoundaryLayer(p,"secondary")

           

        #MessageBox(None, '10', 'updateMessages', 0)

        #Validate SECONDARY boundary column list input

        if in_boundary_lyr_2.value != None and \

          (in_boundary_cols_2.altered == True or in_boundary_alias_cols_2.altered == True) and \

           in_boundary_cols_2.hasError() == False and \

           in_boundary_lyr_2.hasError() == False and \

            lyr_str_2 != "":

 

            self.validate_BoundaryColumns(p,"secondary")

        #MessageBox(None, '11', 'updateMessages', 0)

        #Validate SECONDARY boundary column alias list input

        if in_boundary_lyr_2.value != None and \

          (in_boundary_lyr_2.altered == True or in_boundary_cols_2.altered == True or in_boundary_alias_cols_2.altered == True) and \

           in_boundary_alias_cols_2.hasError() == False:

 

            self.validate_BoundaryAliasColumns(p,"secondary")

        #MessageBox(None, '12', 'updateMessages', 0)

        #Validate SECONDARY text file filter input

        if in_boundary_lyr_2.value != None and \

          (in_boundary_filter_2.altered == True or in_boundary_cols_2.altered == True) and \

           in_boundary_filter_2.hasError() == False and \

           in_boundary_lyr_2.hasError() == False and \

            lyr_str_2 != "":

 

            self.validate_BoundaryFilter(p,"secondary")

        #MessageBox(None, '13', 'updateMessages', 0)

        #Validate pipe size range

        if in_size_from.hasError() == False and in_size_to.hasError() == False:

 

            if in_size_from.altered == True or in_size_to.altered == True:

                self.validate_SizeRange(p)

        #MessageBox(None, '14', 'updateMessages', 0)

        #Validate date range

        if in_date_from.hasError() == False and in_date_to.hasError() == False:

            self.validate_DateRange(p)

        #MessageBox(None, '15', 'updateMessages', 0)

        #Validate year list

        if in_year_list.hasError() == False and in_year_list.altered == True:

            self.validate_YearList(p)

 

        #Validate output directory

        #if out_directory.hasError() == False:

        #self.validate_OutputDirectory(p)

        #MessageBox(None, '16', 'updateMessages', 0)

 

    #-----------------------------------------------------------------------------------

    #Geo processing functions

    #-----------------------------------------------------------------------------------

 

    #Link 2 groups of where statements: (...) AND (...)

    def Link_Where(self, where_str):

        if where_str != "":

            where_str = where_str + " AND "

        where_str = where_str + "("

 

        return where_str

 

    def Create_Point_SQL(self, p):

        where_str = ""

 

        in_date_from = p[self.in_date_from]

        in_date_to = p[self.in_date_to]

        in_year_list = p[self.in_year_list]

 

        in_point_cols = p[self.in_point_cols]

        in_point_cols = str(in_point_cols.value)

 

 

        #Build filter for install date range

        if in_date_from.value != None or in_date_to.value != None:

 

            if in_point_cols.find("INSTALL_") == -1:

                raise Exception("'INSTALL_YEAR' selection is required under 'Point column(s) for report' when querying a date range")

 

            where_str = self.Link_Where(where_str)

 

            if in_date_from.value != None:

                where_str = where_str + "INSTALLATIONDATE >= to_date('" + str(in_date_from.value) + "','YYYY-MM-DD HH24:MI:SS')"

 

            if in_date_to.value != None:

                if in_date_from.value != None:

                    where_str = where_str + " AND "

 

                #Change hh24:mm:ss to 23:59:59 on installation date upper range

                temp_time = str(in_date_to.value)

                temp_date = str(in_date_to.value)

                if len(temp_time) >= 15:

 

                    temp_date = temp_time[0:10]

                    temp_date = temp_date + " 23:59:59"

 

                where_str = where_str + "INSTALLATIONDATE <= to_date('" + temp_date + "','YYYY-MM-DD HH24:MI:SS')"

 

            where_str = where_str + ")"

 

        #Build filter for install year list

        if in_year_list.value != None:

 

            if in_point_cols.find("INSTALL_") == -1:

                raise Exception("'INSTALL_YEAR' selection is required under 'Point column(s) for report' when querying for year(s)")

 

            where_str = self.Link_Where(where_str)

 

            year_list = str(in_year_list.value).split(",")

 

            for i in range(0, len(year_list)):

                if i >= 1:

                    where_str = where_str + " OR "

                where_str = where_str + "EXTRACT(YEAR FROM INSTALLATIONDATE)=" + year_list[i]

 

            where_str = where_str + ")"

 

        where_str = where_str.rstrip()

        where_str = where_str.lstrip()

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Point query: '" + where_str + "'")

 

        return where_str

 

    #Generate where statement for in_memory pipes layer

    def Create_Pipe_SQL(self, p, main_or_service):

        global pipe_col_aliases

        global pipe_col_fields

        global pipe_types

        global material_names

 

        in_pipe_cols = p[self.in_pipe_cols]

        in_pipe_materials = p[self.in_pipe_materials]

        in_pipe_types= p[self.in_pipe_types]

        in_size_from = p[self.in_size_from]

        in_size_to = p[self.in_size_to]

        in_date_from = p[self.in_date_from]

        in_date_to = p[self.in_date_to]

        in_year_list = p[self.in_year_list]

 

        field_list = str(in_pipe_cols.value).split(";")

        material_list = str(in_pipe_materials.value).split(";")

        type_list = str(in_pipe_types.value).split(";")

        where_str = ""

 

        if len(main_or_service) >= 1:

            where_str = "STATUS='Active' "

 

        #Build filter for pipe material type

        if len(material_list) < len(material_names):

            where_str = self.Link_Where(where_str)

 

            for i in range(0, len(material_list)):

                index = material_names.index(material_list[i])

                if i > 0:

                    where_str = where_str + " OR "

                where_str = where_str + "MATERIAL='" + str(material_ids[index]) + "'"

 

            where_str = where_str + ")"

 

        #Build filter for pipe type

        if len(type_list) < len(pipe_types):

            where_str = self.Link_Where(where_str)

 

            for i in range(0, len(type_list)):

                if i >= 1:

                    where_str = where_str + " OR "

 

                #Main or service

                if len(main_or_service) >= 1:

                    where_str = where_str + main_or_service.upper() + "TYPE='" + type_list[i].replace("'","") + "'"

 

                #Abandoned gas pipe

                else:

                    where_str = where_str + "PIPECLASSIFICATION='" + type_list[i].replace("'","") + "'"

 

            where_str = where_str + ")"

 

        #Build filter for pipe size range

        if in_size_from.value != None or in_size_to.value != None:

            where_str = self.Link_Where(where_str)

 

            if in_size_from.value != None:

                where_str = where_str + "DIAMETER >= " + str(in_size_from.value)

 

            if in_size_to.value != None:

                if in_size_from.value != None:

                    where_str = where_str + " AND "

                where_str = where_str + "DIAMETER <= " + str(in_size_to.value)

 

            where_str = where_str + ")"

 

        #Date query in SDE oracle

        #INSTALLATIONDATE >=

        #TO_DATE('2012-01-01', 'YYYY-MM-DD')

 

        #Date query in shp file

        #INSTALLATI >= date '01/01/2012 00:00:00'

 

        #Testing sql developer

        #select TO_CHAR(to_date('2012-11-01 12:10:00','YYYY-MM-DD HH24:MI:SS'),'MM/DD/YYYY HH24:MI') from dual

 

        #Build filter for install date range

        if in_date_from.value != None or in_date_to.value != None:

            where_str = self.Link_Where(where_str)

 

            if in_date_from.value != None:

                where_str = where_str + "INSTALLATIONDATE >= to_date('" + str(in_date_from.value) + "','YYYY-MM-DD HH24:MI:SS')"

 

            if in_date_to.value != None:

                if in_date_from.value != None:

                    where_str = where_str + " AND "

 

                #Change hh24:mm:ss to 23:59:59 on installation date upper range

                temp_time = str(in_date_to.value)

                temp_date = str(in_date_to.value)

                if len(temp_time) >= 15:

 

                    temp_date = temp_time[0:10]

                    temp_date = temp_date + " 23:59:59"

 

                where_str = where_str + "INSTALLATIONDATE <= to_date('" + temp_date + "','YYYY-MM-DD HH24:MI:SS')"

 

            where_str = where_str + ")"

 

        #Build filter for install year list

        if in_year_list.value != None:

            where_str = self.Link_Where(where_str)

 

            year_list = str(in_year_list.value).split(",")

 

            for i in range(0, len(year_list)):

                if i >= 1:

                    where_str = where_str + " OR "

                where_str = where_str + "EXTRACT(YEAR FROM INSTALLATIONDATE)=" + year_list[i]

 

            where_str = where_str + ")"

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Pipe query: '" + where_str + "'")

 

        return where_str

 

    def Add_Intersect_Column(self, aliases, aliasname, fieldname, fieldtype, sqlite_type="default"):

        global pipe_intersect_fields

        global pipe_intersect_types

        global sqlite_types

        global sqlite_fields

        global sqlite_aliases

 

        typestr = ""

        if sqlite_type == "default":

            typestr = fieldtype.lower() #arcpy field type same as sqlite column type

        else:

            typestr = sqlite_type

 

        if aliases.find(aliasname) >= 0:

            pipe_intersect_types.append(fieldtype)

            pipe_intersect_fields.append(fieldname)

 

            sqlite_fields.append(fieldname)

            sqlite_types.append(typestr)

            sqlite_aliases.append(aliasname)

 

    def Add_Intersect_Column_Simple(self, aliasname, fieldname, fieldtype, sqlite_type="default"):

        global pipe_intersect_fields

        global pipe_intersect_types

        global sqlite_types

        global sqlite_fields

        global sqlite_aliases

 

        typestr = ""

        if sqlite_type == "default":

            typestr = fieldtype.lower() #arcpy field type same as sqlite column type

        else:

            typestr = sqlite_type

 

        pipe_intersect_types.append(fieldtype)

        pipe_intersect_fields.append(fieldname)

 

        sqlite_fields.append(fieldname)

        sqlite_types.append(typestr)

        sqlite_aliases.append(aliasname)

 

    def Create_Point_FeatureClass(self, p):

 

        global point_fields

        global point_source_fields

 

        point_fields = []

        point_source_fields = []

 

        in_point_cols = p[self.in_point_cols]

        in_point_cols_str = str(in_point_cols.value)

        #in_facility_layers = p[self.in_facility_layers]

        #in_facility_layers_str = str(in_facility_layers.value)

 

        point_cols = str(in_point_cols.value).split(";")

        point_fc = "in_memory/points"

        temp_str = ""

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Creating temporary point feature class" + self.Time_Elapsed())

 

        #Retrieve spatial reference and subtypes from main (has same reference as service)

        sr = arcpy.Describe("GasFacilities/Main").spatialReference

        arcpy.CreateFeatureclass_management("in_memory","points","POINT","","ENABLED","ENABLED",sr)

 

        arcpy.AddField_management(point_fc, "DIVISION", "TEXT")

        arcpy.AddField_management(point_fc, "LAYER_NAME", "TEXT")

 

        point_fields.append("SHAPE@")

        point_fields.append("DIVISION")

        point_fields.append("LAYER_NAME")

 

        point_source_fields.append("SHAPE@")

        point_source_fields.append("SWGUID") #required

 

        #SWGUID

        if in_point_cols_str.find("SWG_ID") >= 0:

            arcpy.AddField_management(point_fc, "SWG_ID", "TEXT")

            point_fields.append("SWG_ID")

 

        #Add 1 or more fields that user checked

        if len(point_cols) >= 1 and in_point_cols.value != None:

 

            for i in range(0, len(point_cols)):

 

                if len(str(point_cols[i])) >= 1:

 

                    temp_str = str(point_cols[i])

                    temp_str = temp_str.rstrip()

                    temp_str = temp_str.lstrip()

                    temp_str = temp_str.replace("'","")

 

                    if len(temp_str) >= 1 and \

                       temp_str != "XY COORDINATES" and \

                       temp_str != "PREMISE ID" and \

                       temp_str != "SAP PREMISE ID" and \

                       temp_str != "SWG_ID":

 

                        #Install year is integer

                        if temp_str == "INSTALL_YEAR":

                            arcpy.AddField_management(point_fc, temp_str, "LONG")

                        else:

                            arcpy.AddField_management(point_fc, temp_str, "TEXT")

 

                        point_fields.append(temp_str)

 

                        if temp_str == "INSTALL_YEAR":

                            point_source_fields.append("INSTALLATIONDATE")

 

                        #elif temp_str != "SWG_ID":

 

                        else:

                            point_source_fields.append(temp_str)

 

        #XY Coordinates option

        if in_point_cols_str.find("XY COORDINATES") >= 0:

 

            arcpy.AddField_management(point_fc, "X", "FLOAT")

            point_fields.append("X")

            point_source_fields.append("SHAPE@X")

 

            arcpy.AddField_management(point_fc, "Y", "FLOAT")

            point_fields.append("Y")

            point_source_fields.append("SHAPE@Y")

 

        #Premise ID option

        if in_point_cols_str.find("PREMISE ID") >= 0:

 

            arcpy.AddField_management(point_fc, "PREMISE_ID", "TEXT")

            point_fields.append("PREMISE_ID")

 

        if in_point_cols_str.find("SAP PREMISE ID") >= 0:

            arcpy.AddField_management(point_fc, "SAP_PREMISE_ID", "TEXT")

            point_fields.append("SAP_PREMISE_ID")

 

            #arcpy.AddField_management(point_fc, "RISER_SWGUID", "TEXT")

            #point_fields.append("RISER_SWGUID")

 

        #arcpy.AddMessage("test 0: " + ",".join(point_fields))

 

    def Load_Nominal_Diameter_Data(self, c):

 

        #Create table

        sql = "CREATE TABLE outside_diameter_info (nominal real, outside real)"

        arcpy.AddMessage("Loading nominal to outside diameter lookup data" + self.Time_Elapsed())

        arcpy.AddMessage("SQLite create table: " + sql)

        c.execute(sql)

 

        fo = open(os.path.dirname(os.path.realpath(__file__)) + \\OutsideDiameterInfo.csv, "r")

        lines = fo.readlines()

        fo.close()

 

        for d in range(1, len(lines)):

            cols = str(lines[d]).split(",")

 

            sql = "INSERT INTO outside_diameter_info VALUES ('" + str(cols[0]).rstrip() + "','" + str(cols[1]).rstrip() + "')"

            arcpy.AddMessage(str(d) + ": " + sql)

            c.execute(sql)

 

    def Create_Pipe_FeatureClass(self, p):

        global pipe_intersect_fields

        global pipe_intersect_types

        global pipe_source_fields

        global sqlite_types

        global sqlite_fields

        global sqlite_aliases

        global material_names

 

        in_pipe_cols = p[self.in_pipe_cols]

        in_pipe_materials = p[self.in_pipe_materials]

        in_pipe_types = p[self.in_pipe_types]

        in_size_from = p[self.in_size_from]

        in_size_to = p[self.in_size_to]

        in_date_from = p[self.in_date_from]

        in_date_to = p[self.in_date_to]

        in_year_list = p[self.in_year_list]

        in_facility_layers = str(p[self.in_facility_layers].value)

        in_length_type = str(p[self.in_length_type].value)

 

        material_list = str(in_pipe_materials.value).split(";")

        aliases = str(in_pipe_cols.value)

 

        arcpy.AddMessage("aliases: " + aliases)

 

 

        #Reset global collections

        pipe_intersect_types = []

        pipe_intersect_fields = []

        pipe_source_fields = []

##        sqlite_types = []

##        sqlite_fields = []

##        sqlite_aliases = []

 

        pipefc = "in_memory/pipes"

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Creating temporary pipe feature class" + self.Time_Elapsed())

 

        #Retrieve spatial reference and subtypes from main (has same reference as service)

        sr = arcpy.Describe("GasFacilities/Main").spatialReference

        arcpy.CreateFeatureclass_management("in_memory","pipes","POLYLINE","","ENABLED","ENABLED",sr)

 

        #Special case for abandoned gas pipes

        if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

            if len(aliases) >= 1:

                aliases = aliases + ",'Retired Year'"

            else:

                aliases = "'Retired Year'"

 

            pipe_source_fields.append("RETIREDDATE")

 

        #aliases = aliases + ",'System MOP'"

        self.Add_Intersect_Column_Simple("Division","DIVISION","TEXT")

        self.Add_Intersect_Column(aliases,"Pipe Layer Name","LAYERNAME","TEXT")

        self.Add_Intersect_Column(aliases,"Main or Service","FEATURETYPE","TEXT")

 

        if aliases.find("Pipe Type") >= 0 or in_pipe_types != None:

            self.Add_Intersect_Column_Simple("Pipe Type","TYPE","TEXT")

 

        if aliases.find("Material") >= 0 or len(material_list) < len(material_names):

            self.Add_Intersect_Column_Simple("Material","MATERIAL","TEXT")

 

        if aliases.find("Size") >= 0 or in_size_from.value != None or in_size_to.value != None:

            self.Add_Intersect_Column_Simple("Diameter","DIAMETER","DOUBLE")

 

       

        self.Add_Intersect_Column(aliases,"Wall Thickness","WALLTHICKNESS","DOUBLE")

        self.Add_Intersect_Column(aliases,"Grade","GRADE","TEXT")

        self.Add_Intersect_Column(aliases,"M-Rec Complete","M_REC_COMPLETE","TEXT")

        self.Add_Intersect_Column(aliases,"M-Rec Method (0-6)","REC_DIVREC_METHOD","LONG")

        self.Add_Intersect_Column(aliases,"Test Pressure","TESTPRESSURE","DOUBLE")

 

        self.Add_Intersect_Column(aliases,"Inside Diameter","ACTUALINTERNALDIAMETER","DOUBLE")

 

        #Install date required

        if aliases.find("Year") >= 0 or \

           aliases.find("Month") >= 0 or \

           in_date_from.value != None or \

           in_date_to.value != None or \

           in_year_list.value != None:

 

            pipe_source_fields.append("INSTALLATIONDATE")

 

        self.Add_Intersect_Column(aliases,"Install Year","INST_YEAR","LONG","integer")

        self.Add_Intersect_Column(aliases,"Install Month","INST_MONTH","LONG","integer")

        self.Add_Intersect_Column(aliases,"Manufacturer","MANUFACTURER","TEXT")

 

        self.Add_Intersect_Column(aliases,"FName","FNAME","TEXT")

        self.Add_Intersect_Column(aliases,"LName","LNAME","TEXT")

 

        self.Add_Intersect_Column(aliases,"OpsSysName","OPSSYSNAME","TEXT")

        self.Add_Intersect_Column(aliases,"PIMSysName","PIMSYSNAME","TEXT")

 

        self.Add_Intersect_Column(aliases,"Job / WR Number","JOBNUMBER","TEXT")

 

        self.Add_Intersect_Column(aliases,"Joint Trench: Electric","JTELECTRIC","TEXT")

        self.Add_Intersect_Column(aliases,"Joint Trench: Telephone","JTTELEPHONE","TEXT")

        self.Add_Intersect_Column(aliases,"Joint Trench: Water","JTWATER","TEXT")

        self.Add_Intersect_Column(aliases,"Joint Trench: Sewer","JTSEWER","TEXT")

        self.Add_Intersect_Column(aliases,"Joint Trench: Gas","JTGAS","TEXT")

 

        self.Add_Intersect_Column(aliases,"MAOP Determinant","MAOPDETERMINANT","LONG","integer")

 

        self.Add_Intersect_Column(aliases,"Segment MAOP","SEGMENTMAOP","LONG","integer")

 

        #self.Add_Intersect_Column(aliases,"System MOP","SYSMOP","LONG","integer")

        #self.Add_Intersect_Column(aliases,"System MAOP","SYSMAOP","LONG","integer")

 

        self.Add_Intersect_Column(aliases,"SWG ID","SWGUID","TEXT")

        self.Add_Intersect_Column(aliases,"Status","STATUS","TEXT")

 

        #GKN1 CRQ000000026545

        self.Add_Intersect_Column(aliases,"Admin Flag","ADMINFLAG","TEXT")

 

        #CGF2 29NOV2016 -- CRQ000000035499

        self.Add_Intersect_Column(aliases,"MAOP Subsystem","MAOP_SUBSYSTEM","TEXT")

 

        #MAR5 31MAY2017 -- CRQ000000059380

        self.Add_Intersect_Column(aliases,"Service Object SWGUID","SERVICEOBJECTSWGUID","TEXT")

        #MAR5 14NOV2017 -- CRQ000000035499

        #endpoints

        if aliases.find("XY Endpoint") >= 0:

            pipe_intersect_fields.append("ENDPOINTX")

            pipe_intersect_types.append("TEXT")

 

            pipe_source_fields.append("SHAPE@")

 

            sqlite_fields.append("ENDPOINTX")

            sqlite_types.append("TEXT")

            sqlite_aliases.append("X Endpoint")

 

            pipe_intersect_fields.append("ENDPOINTY")

            pipe_intersect_types.append("TEXT")

 

            pipe_source_fields.append("SHAPE@")

 

            sqlite_fields.append("ENDPOINTY")

            sqlite_types.append("TEXT")

            sqlite_aliases.append("Y Endpoint")  

        #Build main/service field name collection that match intersect field names

        for i in range(0, len(pipe_intersect_fields)):

            if pipe_intersect_fields[i] != "INST_YEAR" and \

               pipe_intersect_fields[i] != "INST_MONTH" and \

               pipe_intersect_fields[i] != "X" and \

               pipe_intersect_fields[i] != "Y" and \

               pipe_intersect_fields[i] != "ENDPOINTX" and \

               pipe_intersect_fields[i] != "ENDPOINTY":

 

                pipe_source_fields.append(pipe_intersect_fields[i])

 

        #Special case for retired

        #arcpy.AddMessage("test: " + in_facility_layers)

 

        if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

            self.Add_Intersect_Column(aliases,"Retired Year","RETIREDDATE","LONG","integer")

 

        self.Add_Intersect_Column_Simple("Main Length","MAIN_LEN","DOUBLE")

        self.Add_Intersect_Column_Simple("Service Length","SERVICE_LEN","DOUBLE")

 

        if aliases.find("System MOP") >= 0:

            self.Add_Intersect_Column_Simple("System MOP","SYSMOP","DOUBLE")

            self.Add_Intersect_Column_Simple("OUTSIDE_DIAMETER","OUTSIDE_DIAMETER","DOUBLE")

            self.Add_Intersect_Column_Simple("YIELD","YIELD","LONG")

 

        if aliases.find("System MOP") >= 0 and aliases.find("Grade") >= 0 and aliases.find("Wall Thickness") >= 0:

            self.Add_Intersect_Column_Simple("SMYS","SMYS","DOUBLE")

 

        if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

            self.Add_Intersect_Column_Simple("Abandoned Main Length","AB_MAIN_LEN","DOUBLE")

            self.Add_Intersect_Column_Simple("Abandoned Service Length","AB_SERVICE_LEN","DOUBLE")

 

        if in_length_type == "Shape Length":

            self.Add_Intersect_Column_Simple("Shape Length","REC_LEN","DOUBLE")

            self.Add_Intersect_Column_Simple("Original Shape Length","ORIG_LEN","DOUBLE")

        else:

            self.Add_Intersect_Column_Simple("Recorded Length","REC_LEN","DOUBLE")

            self.Add_Intersect_Column_Simple("Original Recorded Length","ORIG_LEN","DOUBLE")

 

 

        #Special case for SYSMAOP

        if aliases.find("System MAOP") >= 0:

            # pipe_intersect_fields.append("SYSMAOP")

            # pipe_intersect_types.append("TEXT")

 

            sqlite_fields.append("SYSMAOP")

            sqlite_types.append("text")

            sqlite_aliases.append("System MAOP")

 

        for i in range(0, len(pipe_intersect_types)):

            arcpy.AddField_management(pipefc, pipe_intersect_fields[i], pipe_intersect_types[i])

 

    #Build global collection of column names for ArcPy InsertCursor and SQLLite inserts

    def BuildInsert(self, insert_vals, fields, row, fieldname):

        i = 0

        try:

            i = fields.index(fieldname)

        except ValueError:

            i = -1

 

        if i >= 0:

            insert_vals.append(row[i])

 

        #Testing

        #if fieldname == "FEATURETYPE":

        #    arcpy.AddMessage("FEATURETYPE test: " + ",".join(fields) + ": " + str(i))

 

        return insert_vals

 

    #Load a point feature class into in_memory ArcPy workspace

    def Load_Point_Data(self, p, c, point_fc):

 

        global point_fields

        global point_source_fields

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Taking snapshot of " + point_fc + self.Time_Elapsed())

 

        premise_ids = []

        temp_insert_vals = []

        offset = 0

        count = 0

        ic = arcpy.da.InsertCursor("in_memory/points", point_fields)

 

        #Generate definition query

        where_str = self.Create_Point_SQL(p)

 

        #arcpy.AddMessage("point snapshot fields: " + ",".join(point_fields))

        #arcpy.AddMessage("point source fields: " + ",".join(point_source_fields))

        #self.List_Fields("in_memory/points")

 

        # Make a layer and select features that overlap the boundary polygon

        # arcpy.AddMessage("Make a layer and select features that overlap the boundary polygon")

        # point_fc_data = arcpy.SelectLayerByLocation_management(point_fc_raw, 'INTERSECT', "in_memory/boundaries")

 

        # point_fc=point_fc_raw+"_1"

        # arcpy.MakeFeatureLayer_management(point_fc_data, point_fc)

 

    

        #Include SAPDATA Layer into GFQR

        if str(point_fc).find("SAPDATA") >= 0:

            point_source_fields.remove("SWGUID") if "SWGUID" in point_source_fields else None

            point_source_fields.append("DIVISION") if "DIVISION" not in point_source_fields else None

        else:

            point_source_fields.remove("DIVISION") if "DIVISION" in point_source_fields else None

            point_source_fields.append("SWGUID") if "SWGUID" not in point_source_fields else None

 

        try:

            row = None

            cursor = None

            cursor = arcpy.da.SearchCursor(point_fc, point_source_fields, where_str)

 

            #Check if install_year is required

            try:

                inst_date_offset = point_source_fields.index("INSTALLATIONDATE")

            except ValueError:

                inst_date_offset = -1

 

            #Check if premise ID is required

            try:

                premise_id_offset = point_fields.index("PREMISE_ID")

            except ValueError:

                premise_id_offset = -1

 

            #Check if SWG ID is required

            try:

                swg_id_offset = point_fields.index("SWG_ID")

            except ValueError:

                swg_id_offset = -1

 

            #arcpy.AddMessage("test: " + str(swg_id_offset))

 

            for row in cursor:

 

                #arcpy.AddMessage("test: " + str(count))

 

                insert_vals = [] #Insert values collection

 

                #Shape

                insert_vals.append(row[0])

    

                #Derive division from first 3 characters of SWGUID

                if "SWGUID" in point_source_fields:                  

                    insert_vals.append(str(row[1][0:3]))

                elif "DIVISION" in point_source_fields:

                    insert_vals.append(str(row[1]))              

  

                #GIS pipe layer name

                insert_vals.append(str(point_fc))

 

                #Add SWGUID

                if swg_id_offset >= 0:

                    insert_vals.append(str(row[1]))

 

                #Everything else

                for i in range(2, len(row)):

 

                    #Install year

                    if i == inst_date_offset:

                        if row[inst_date_offset] != None:

                            insert_vals.append(int(str(row[i])[0:4]))

                        else:

                            insert_vals.append(1800)

 

                    else:

                        insert_vals.append(row[i])

 

                #Premise ID SQLite query (sometimes there is 2 or more premise ID's per riser!!)

                if premise_id_offset >= 0:

 

                    premise_ids = []

                    sap_premise_ids = []

                    c2 = c.execute("SELECT PREMISEID,SAPPREMISEID FROM premise WHERE RISERSWGUID='" + str(row[1]) + "'")

                    for r2 in c2:

                        premise_ids.append(str(r2[0]))

                        sap_premise_ids.append(str(r2[1]))

 

                    #1 or more Premise IDs found

                    if len(premise_ids) >= 1:

 

                        #if len(premise_ids) >= 2:

                        #    arcpy.AddMessage("join test: " + ",".join(premise_ids))

 

                        for i in range(0, len(premise_ids)):

 

                            temp_insert_vals = list(insert_vals)

                            temp_insert_vals.append(premise_ids[i])

                            temp_insert_vals.append(sap_premise_ids[i])

                            #temp_insert_vals.append(str(row[1])) #SWGUID

 

                            # #Testing

                            # test_str = ""

                            # for d in range(0, len(temp_insert_vals)):

                            #    test_str = test_str + "," + str(temp_insert_vals[d])

 

                            # arcpy.AddMessage("Insert Row: " + test_str)

                            # arcpy.AddMessage("Insert Col Names: " + ",".join(point_fields))

                            # arcpy.AddMessage("Insert count: " + str(len(temp_insert_vals)))

 

                            ic.insertRow(temp_insert_vals)

 

                    #If there is no matching premise ID(s)

                    else:

 

                        temp_insert_vals = list(insert_vals)

                        temp_insert_vals.append("")

                        temp_insert_vals.append("")

 

                        ic.insertRow(temp_insert_vals)

 

                #Premise ID reporting is not needed

                else:

                    ic.insertRow(insert_vals)

 

                count = count + 1

                if count > 0 and count % 50000 == 0:

                    arcpy.AddMessage(str(count) + " " + point_fc + " records copied" + self.Time_Elapsed())

 

                    #Testing

                    #break

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        arcpy.AddMessage(str(count) + " point records copied")

        arcpy.AddMessage("Snapshot of " + point_fc + " loaded" + self.Time_Elapsed())

    #MAR5 17NOV2017 CRQ000000035499

    #inserts X or Y coordinate to collection - adapted from BuildInsert function for xy coordinates

    def get_XY_end(self, insert_vals, fields,row,fieldname,xory):

        i = 0

        try:

            i = fields.index(fieldname)

        except ValueError:

            i = -1

 

        if i >= 0:

            endpoint="0"

            for feat in row[i]:

                if xory.upper()=="X":

                    endpoint = str(feat[0].X)

                elif xory.upper()=="Y":

                    endpoint = str(feat[0].Y)

            insert_vals.append(endpoint)

 

        return insert_vals

 

       

    #Load a pipe feature class into in_memory ArcPy workspace

    def Load_Pipe_Data(self, p, pipe_fc, c):

 

        global pipe_source_fields

        global pipe_intersect_fields

        global material_names

        global material_ids

 

        temp_division = ""

 

        in_pipe_cols = p[self.in_pipe_cols]

        in_facility_layers = str(p[self.in_facility_layers].value)

        in_length_type = str(p[self.in_length_type].value)

 

        aliases = str(in_pipe_cols.value)

        insert_year = False

        insert_month = False

 

        if aliases.find("Year") >= 0:

            insert_year = True

        if aliases.find("Month") >= 0:

            insert_month = True

 

        main_or_service = ""

        testcount = 0

        count = 0

 

        # Make a layer and select features that overlap the boundary polygon

        # arcpy.AddMessage("Make a layer and select features that overlap the boundary polygon")

        # pipe_fc_data = arcpy.SelectLayerByLocation_management(pipe_fc_raw, 'INTERSECT', "in_memory/boundaries")

 

        # pipe_fc=pipe_fc_raw+"_1"

        # arcpy.MakeFeatureLayer_management(pipe_fc_data, pipe_fc)

 

 

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Taking snapshot of " + pipe_fc + self.Time_Elapsed())

        fields = []

 

        #Determine if table is main or service

        if self.fieldExists(pipe_fc, "MAINTYPE") == True:

            main_or_service = "Main"

        elif self.fieldExists(pipe_fc, "SERVICETYPE") == True:

            main_or_service = "Service"

        elif pipe_fc.find("Abandoned") >= 0:

            main_or_service = ""

        else:

            raise Exception(pipe_fc + " must contain a field named MAINTYPE, SERVICETYPE, or PIPECLASSIFICATION")

 

        #arcpy.AddMessage("pipe_source_fields: " + ",".join(pipe_source_fields))

        #arcpy.AddMessage("pipe_fc: " + pipe_fc)

 

        #Define list of fields from SDE main or service table

        for i in range(0, len(pipe_source_fields)):

 

            if pipe_source_fields[i] == "TYPE":

 

                if main_or_service == "Main":

                    fields.append("MAINTYPE")

                elif main_or_service == "Service":

                    fields.append("SERVICETYPE")

 

                #Abandoned pipe feature class

                else:

                    fields.append("PIPECLASSIFICATION")

 

            #Special case for pressure data not available in Service table

            elif main_or_service == "Service" and \

                (pipe_source_fields[i] == "SEGMENTMAOP" or \

                 pipe_source_fields[i] == "SYSMOP" or \

                 pipe_source_fields[i] == "SYSMAOP"):

 

                print ""

                #arcpy.AddMessage(pipe_source_fields[i] + " not available in Service table")

            #MAR5 31MAY2017 - CRQ000000059380

            #Spcial case for Service Object SWGUID

            elif main_or_service == "Main" and pipe_source_fields[i] == "SERVICEOBJECTSWGUID":

                print ""

            #Special case for pipe layer name

            elif pipe_source_fields[i] == "LAYERNAME":

                print ""

            #MAR5 14NOV2017 - CRQ000000035499

            elif pipe_source_fields[i] == "SHAPE@X" or pipe_source_fields[i] == "SHAPE@Y" or  pipe_source_fields[i] == "SHAPE@":

                fields.append(pipe_source_fields[i])

            #Special case for division

            elif pipe_source_fields[i] == "DIVISION":

                fields.append("SWGUID")

 

            #Special case for retired year

            elif pipe_source_fields[i] == "RETIREDDATE":

 

                #arcpy.AddMessage("test 1")

 

                if pipe_fc.find("Abandoned Gas Pipe") >= 0:

 

                    #arcpy.AddMessage("test 2")

                    fields.append("RETIREDDATE")

 

            #All other fields except for install year and month

            elif pipe_source_fields[i].find("INST_") == -1:

 

                fields.append(pipe_source_fields[i])

       

        #Special case for Abandoned gas pipe retired year

        if pipe_fc.find("Abandoned Gas Pipe") >= 0:

            #arcpy.AddMessage("add retired date")

            fields.append("RETIREDDATE")

 

        if in_length_type == "Shape Length":

            fields.append("SHAPE@LENGTH")

        else:

            fields.append("RECORDEDLENGTH")

 

        fields.append("SHAPE@LENGTH")

        fields.append("SHAPE@")

 

        temp_fields = list(pipe_intersect_fields)

        temp_fields.append("SHAPE@")

 

        #Remove SYSMOP and SYSMAOP from pipe feature class search query

        try:

            if aliases.find("System MOP") < 0:

                #temp_fields.remove("SYSMOP")

                if "SYSMAOP" in temp_fields: temp_fields.remove("SYSMAOP")

                if "OUTSIDE_DIAMETER" in temp_fields: temp_fields.remove("OUTSIDE_DIAMETER")

                if "YIELD" in temp_fields: temp_fields.remove("YIELD")

                if "SMYS" in temp_fields: temp_fields.remove("SMYS")   

        except:

            pass

 

        arcpy.AddMessage("temp_fields: " + ",".join(temp_fields))

        arcpy.AddMessage("fields: " + ",".join(fields))

 

        ic = arcpy.da.InsertCursor("in_memory/pipes", temp_fields)

 

 

        if main_or_service != "Main":

            if "WALLTHICKNESS" in fields: fields.remove("WALLTHICKNESS")

            if "GRADE" in fields: fields.remove("GRADE")

            if "M_REC_COMPLETE" in fields: fields.remove("M_REC_COMPLETE")

            if "REC_DIVREC_METHOD" in fields: fields.remove("REC_DIVREC_METHOD")

            if "TESTPRESSURE" in fields: fields.remove("TESTPRESSURE")  

 

 

        arcpy.AddMessage("temp_fields: " + ",".join(temp_fields))

        arcpy.AddMessage(pipe_fc + " fields: " + ",".join(fields))

 

        #Generate definition query

        where_str = self.Create_Pipe_SQL(p, main_or_service)

       

        try:

 

            row = None

            cursor = None

 

            cursor = arcpy.da.SearchCursor(pipe_fc, fields, where_str)

            for row in cursor:

 

                insert_vals = [] #Insert values collection

                offset = 0

 

                #Derive division from first 3 characters of pipe id

                try:

                    offset = fields.index("SWGUID")

                except ValueError:

                    offset = -1

 

                if offset >= 0:

                    try:

                        if str(row[offset][0:2]) == "GB":

                            insert_vals.append(str(row[offset][0:2]))

                        else:

                            insert_vals.append(str(row[offset][0:3]))

                    except:

                        raise Exception("Blank or invalid " + pipe_fc + " SWGUID found")

 

                #GIS pipe layer name

                try:

                    offset = temp_fields.index("LAYERNAME")

                except ValueError:

                    offset = -1

 

                if offset >= 0:

                    insert_vals.append(pipe_fc)

 

                #Main or Service

                self.BuildInsert(insert_vals,fields,row,"FEATURETYPE")

 

                #Fetch temp variable for Abandoned Gas Pipe main or service classification

                temp_main_or_service = str(insert_vals[len(insert_vals)-1])

 

                #SNV Prod has 2 null records !!

                #arcpy.AddMessage("temp_main_or_service: " + temp_main_or_service)

 

                #Pipe type from maintype or servicetype

                if len(main_or_service) >= 1:

                    self.BuildInsert(insert_vals,fields,row,main_or_service.upper() + "TYPE")

 

                #Abandoned pipe special case

                else:

                    self.BuildInsert(insert_vals,fields,row,"PIPECLASSIFICATION")

 

                #pipe material special case (Decode material type from material ID)

                try:

                    offset = fields.index("MATERIAL")

                except ValueError:

                    offset = -1

 

                if offset >= 0:

                    for m in xrange(0, len(material_ids)):

                        if row[offset] == material_ids[m]:

                            insert_vals.append(material_names[m])

                            break

 

                self.BuildInsert(insert_vals,fields,row,"DIAMETER")

 

                if main_or_service == "Main":

                    self.BuildInsert(insert_vals,fields,row,"WALLTHICKNESS")

                    self.BuildInsert(insert_vals,fields,row,"GRADE")

                    self.BuildInsert(insert_vals,fields,row,"M_REC_COMPLETE")

                    self.BuildInsert(insert_vals,fields,row,"REC_DIVREC_METHOD")

                    self.BuildInsert(insert_vals,fields,row,"TESTPRESSURE")             

                else :

 

                    if "WALLTHICKNESS" in temp_fields: insert_vals.append(None) #"WALLTHICKNESS"

                    if "GRADE" in temp_fields: insert_vals.append(None) #"GRADE"

                    if "M_REC_COMPLETE" in temp_fields: insert_vals.append(None) #"M_REC_COMPLETE"

                    if "REC_DIVREC_METHOD" in temp_fields: insert_vals.append(None) #"REC_DIVREC_METHOD"

                    if "TESTPRESSURE" in temp_fields: insert_vals.append(None) #"TESTPRESSURE"                          

 

                self.BuildInsert(insert_vals,fields,row,"ACTUALINTERNALDIAMETER")   

 

                #install year and install month

                try:

                    offset = fields.index("INSTALLATIONDATE")

                except ValueError:

                    offset = -1

 

                if offset >= 0:

 

                    #Format: 1965-01-01 00:00:00

                    if insert_year == True:

                        if row[offset] != None:

                            insert_vals.append(int(str(row[offset])[0:4]))

                        else:

                            insert_vals.append(1800)

 

                    if insert_month == True:

                        if row[offset] != None:

                            insert_vals.append(int(str(row[offset])[5:7]))

                        else:

                            insert_vals.append(1)

 

                self.BuildInsert(insert_vals,fields,row,"MANUFACTURER")

 

                self.BuildInsert(insert_vals,fields,row,"FNAME")

                self.BuildInsert(insert_vals,fields,row,"LNAME")

                self.BuildInsert(insert_vals,fields,row,"SYSMOP")

                self.BuildInsert(insert_vals,fields,row,"OPSSYSNAME")

                self.BuildInsert(insert_vals,fields,row,"PIMSYSNAME")

                self.BuildInsert(insert_vals,fields,row,"JOBNUMBER")

                self.BuildInsert(insert_vals,fields,row,"JTELECTRIC")

                self.BuildInsert(insert_vals,fields,row,"JTTELEPHONE")

                self.BuildInsert(insert_vals,fields,row,"JTWATER")

                self.BuildInsert(insert_vals,fields,row,"JTSEWER")

                self.BuildInsert(insert_vals,fields,row,"JTGAS")

 

                self.BuildInsert(insert_vals,fields,row,"MAOPDETERMINANT")

 

                if main_or_service == "Main":

                    self.BuildInsert(insert_vals,fields,row,"SEGMENTMAOP")

 

                    #4/28/2015 update here:

 

                    #Run SQLite UPDATE statement instead against MAIN snapshot,

                    #to pull in data from GasPressureSystem table

 

                    if aliases.find("System MOP") >= 0:

                        if aliases.find("OpsSysName") == -1:

                            raise Exception("OpsSysName in main/service column selection is required when reporting on System MOP")

 

                        #insert_vals.append(None)

 

                    if aliases.find("System MAOP") >= 0:

                        if aliases.find("OpsSysName") == -1:

                            raise Exception("OpsSysName in main/service column selection is required when reporting on System MAOP")

                        else:

                            self.BuildInsert(insert_vals,fields,row,"SYSMAOP")

                        #insert_vals.append(None)

 

                    #self.BuildInsert(insert_vals,fields,row,"SYSMOP")

                    #self.BuildInsert(insert_vals,fields,row,"SYSMAOP")

 

                #3 pressure fields don't exist in Service table

                else:

                    if aliases.find("Segment MAOP") >= 0:

                        insert_vals.append(None)

 

                    if aliases.find("System MOP") >= 0:

                        if aliases.find("OpsSysName") == -1:

                            raise Exception("OpsSysName in main/service column selection is required when reporting on System MOP")

                        #insert_vals.append(None)

 

                    if aliases.find("System MAOP") >= 0:

                        if aliases.find("OpsSysName") == -1:

                            raise Exception("OpsSysName in main/service column selection is required when reporting on System MAOP")

                        else:

                            self.BuildInsert(insert_vals,fields,row,"SYSMAOP")                    

                        #insert_vals.append(None)

 

                if aliases.find("SWG ID") >= 0:

                    self.BuildInsert(insert_vals,fields,row,"SWGUID")

 

                self.BuildInsert(insert_vals,fields,row,"STATUS")

 

                #GKN1 CRQ000000026545

                self.BuildInsert(insert_vals,fields,row,"ADMINFLAG")

 

                #CGF2 29NOV2016 -- CRQ000000035499

                self.BuildInsert(insert_vals,fields,row,"MAOP_SUBSYSTEM")

 

                #MAR5 31MAY2017 - CRQ000000059380

                if main_or_service == "Service":

                    self.BuildInsert(insert_vals,fields,row,"SERVICEOBJECTSWGUID")

                else:

                    if aliases.find("Service Object SWGUID") >=0:

                        insert_vals.append(None)

 

                #MAR5 14NOV2017 - CRQ000000035499

                if aliases.find("XY Endpoint") >=0:

                    self.get_XY_end(insert_vals,fields,row,"SHAPE@","X")

                    self.get_XY_end(insert_vals,fields,row,"SHAPE@","Y")

                                     

                #Retired year

                if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

 

                    try:

                        offset = fields.index("RETIREDDATE")

                    except ValueError:

                        offset = -1

 

                    #arcpy.AddMessage("insert test: abandoned pipes: " + str(offset))

 

                    if offset >= 0:

                        if row[offset] != None:

                            insert_vals.append(int(str(row[offset])[0:4]))

                        else:

                            insert_vals.append(None)

                    else:

                        insert_vals.append(None)

 

 

                #Main and service length (copied from RECORDED LENGTH)

                #if main_or_service == "Main":

 

                #    insert_vals.append(row[len(row)-3]) #main length

                #    insert_vals.append(0) #service length

 

                #elif main_or_service == "Service":

 

                #   insert_vals.append(0) #main length

                #   insert_vals.append(row[len(row)-3]) #service length

 

                #Pipe layer selection contains abandoned gas pipe layer

                if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

 

                    if main_or_service != "":

                        if main_or_service == "Main":

                            insert_vals.append(row[len(row)-3]) #main length

                            insert_vals.append(0)

                            insert_vals.append(0)

                            insert_vals.append(0)

 

                        elif main_or_service == "Service":

                            insert_vals.append(0)

                            insert_vals.append(row[len(row)-3]) #service length

                            insert_vals.append(0)

                            insert_vals.append(0)

 

                    else:

                        if temp_main_or_service == "Main":

                            insert_vals.append(0)

                            insert_vals.append(0)

                            insert_vals.append(row[len(row)-3]) #abandoned main length

                            insert_vals.append(0)

 

                        elif temp_main_or_service == "Service":

                            insert_vals.append(0)

                            insert_vals.append(0)

                            insert_vals.append(0)

                            insert_vals.append(row[len(row)-3]) #abandoned service length

 

                        else:

                            #MAR5 14NOV2017 - CRQ000000052026

                            #updated from "'Main or Service' report column must be selected when reporting on Abandoned Gas Pipes"

                            raise Exception("'Main or Service' report column must be selected and the FEATURETYPE field cannot contain Null values when reporting on Abandoned Gas Pipes")

 

                else:

                    if main_or_service == "Main":

 

                        insert_vals.append(row[len(row)-3]) #main length

                        insert_vals.append(0) #service length

 

                    elif main_or_service == "Service":

 

                        insert_vals.append(0) #main length

                        insert_vals.append(row[len(row)-3]) #service length

 

                    if aliases.find("System MOP") >= 0:

                        insert_vals.append(0) #SYSMOP

                        insert_vals.append(0) #OUTSIDE_DIAMETER

                        insert_vals.append(0) #YIELD

                    if aliases.find("System MOP") >= 0 and aliases.find("Grade") >= 0 and aliases.find("Wall Thickness") >= 0:

                        insert_vals.append(0) #SMYS

 

                #Recorded length, shape length, and geometry

                insert_vals.append(row[len(row)-3])

                insert_vals.append(row[len(row)-2])

                insert_vals.append(row[len(row)-1])

 

                # #Testing

                # test_str = ""

                # for d in range(0, len(insert_vals)):

                #    test_str = test_str + "," + str(insert_vals[d])

 

                # arcpy.AddMessage("Insert Row: " + test_str)

                # arcpy.AddMessage("Insert Col Names: " + ",".join(temp_fields))

                # arcpy.AddMessage("Insert count: " + str(len(insert_vals)))

 

                ic.insertRow(insert_vals)

               

                count = count + 1

                if count > 0 and count % 25000 == 0:

                    arcpy.AddMessage(str(count) + " " + pipe_fc + " records copied" + self.Time_Elapsed())

 

            #Testing

            #break

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            # test_str = ""

            # for d in range(0, len(insert_vals)):

            #    test_str = test_str + "," + str(insert_vals[d])

 

            # arcpy.AddMessage("Insert Row: " + test_str)

            # arcpy.AddMessage("Insert Col Names: " + ",".join(temp_fields))

            # arcpy.AddMessage("Insert count: " + str(len(insert_vals)))

            if row:

                del row

            if cursor:

                del cursor

 

        #Testing

        #raise Exception("test completed")

 

        arcpy.AddMessage(arcpy.GetCount_management("in_memory/pipes").getOutput(0) + " pipe records copied")

        arcpy.AddMessage("Snapshot of " + pipe_fc + " loaded" + self.Time_Elapsed())

 

    def Create_Boundary_SQL(self, p, primary_secondary = "primary"):

 

        if primary_secondary == "primary":

            in_boundary_filter = p[self.in_boundary_filter]

            in_boundary_cols = p[self.in_boundary_cols]

        else:

            in_boundary_filter = p[self.in_boundary_filter_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

 

        where_str = ""

 

        if in_boundary_filter.value != None:

 

            #Open filter text file

            lines = open(str(in_boundary_filter.value), 'r').readlines()

 

            #Read file header

            header_columns = lines[0].split("|")

 

            #Loop through each file header column

            for i in range(0, len(header_columns)):

 

                where_str = self.Link_Where(where_str)

 

                #Build where statement for each column

                for d in range(1, len(lines)):

                    data_columns = lines[d].split("|")

 

                    if d >= 2:

                        where_str = where_str + " OR "

                    where_str = where_str + "\"" + header_columns[i].replace("\n","") + "\"='" + data_columns[i].replace("\n","") + "'"

                where_str = where_str + ")"

 

        #Create boundary feature layer

        arcpy.AddMessage("Boundary SQL Filter: " + where_str)

 

        return where_str

 

    def Create_Temp_Boundary_Lyr(self, in_boundary_lyr):

        arcpy.CopyFeatures_management(in_boundary_lyr, "in_memory/temp_boundary")

 

        count = int(arcpy.GetCount_management("in_memory/temp_boundary").getOutput(0))

        if count == 0:

            raise Exception("Unable to read records from " + in_boundary_lyr + \

                            ". Please contact a GIS administrator to remove database locks on " + in_boundary_lyr + ".")

 

    #Build snapshot of boundary feature class

    def Create_Boundary_FeatureClass(self, p, primary_secondary = "primary"):

        global sqlite_fields

        global sqlite_types

        global sqlite_aliases

 

        suffix = ""

        output_fc = ""

        boundary_fullpath = ""

        total = 0

 

        if primary_secondary == "primary":

            in_boundary_lyr = p[self.in_boundary_lyr]

            in_boundary_cols = p[self.in_boundary_cols]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols]

 

            output_fc = "in_memory/boundaries"

            fc = "boundaries"

            suffix = "_1"

 

        else:

            in_boundary_lyr = p[self.in_boundary_lyr_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols_2]

 

            output_fc = "in_memory/boundaries_2"

            fc = "boundaries_2"

            suffix = "_2"

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Taking snapshot of " + str(in_boundary_lyr.value) + self.Time_Elapsed())

 

        #Copy to temp location

        self.Create_Temp_Boundary_Lyr(str(in_boundary_lyr.value))

 

        #Get layer path

        lyr = arcpy.mapping.Layer(in_boundary_lyr.value)

        boundary_fullpath = lyr.name

        arcpy.AddMessage("Layer source: " + boundary_fullpath)

 

        boundary_col_list = str(in_boundary_cols.value).split(",")

        boundary_aliases = str(in_boundary_alias_cols.value).split(",")

 

        source_fields = arcpy.ListFields(in_boundary_lyr.value)

        source_fieldnames = []

 

        output_fields = [] #List of fields to copy from source

        output_field_types =[]

        input_fields = []

 

        #Check if fields exists

        for i in range(0, len(boundary_col_list)):

            if self.fieldExists(str(in_boundary_lyr.value), boundary_col_list[i]) == False:

                raise Exception(boundary_col_list[i] + " field does not exist in " + str(in_boundary_lyr.value))

                break

 

        #Get list of field names from source that match user-defined boundary field list

        for i in range(0, len(boundary_col_list)):

            for field in source_fields:

                if boundary_col_list[i] == field.name:

 

                    temp_type = str(field.type).upper()

 

                    #Add "_2" Suffix to field names for secondary boundary

 

                    sqlite_fields.append(str(field.name) + suffix)

                    sqlite_aliases.append(boundary_aliases[i].replace("'",""))

 

                    input_fields.append(str(field.name) + suffix)

 

                    output_fields.append(str(field.name))

                    output_field_types.append(temp_type)

 

                    #Translate to SQlite types

                    if temp_type.find("INT") >= 0:

                        sqlite_types.append("integer")

                    elif temp_type.find("LONG") >= 0 or temp_type.find("SINGLE") >= 0 or temp_type.find("DOUBLE") >= 0:

                        sqlite_types.append("double")

                    else:

                        sqlite_types.append("text")

 

                    break

 

        #Create boundary feature class in memory

        sr = arcpy.Describe(in_boundary_lyr.value).spatialReference

        arcpy.CreateFeatureclass_management("in_memory",fc,"POLYGON","","DISABLED","DISABLED",sr)

 

        for i in range(0, len(output_fields)):

            arcpy.AddField_management(output_fc, input_fields[i], output_field_types[i])

 

        #Add shape column

        input_fields.append("SHAPE@")

        output_fields.append("SHAPE@")

        where_str = self.Create_Boundary_SQL(p, primary_secondary)

 

        #Copy data from source boundary feature class

        ic = arcpy.da.InsertCursor(output_fc, input_fields)

 

        try:

            row = None

            cursor = None

 

            #"in_memory/temp_boundary"

            #cursor = arcpy.da.SearchCursor(boundary_fullpath, output_fields,where_str)

 

            cursor = arcpy.da.SearchCursor("in_memory/temp_boundary", output_fields,where_str)

            for row in cursor:

                rowvals = []

                for i in range(0, len(output_fields)):

                    rowvals.append(row[i])

 

                ic.insertRow(rowvals)

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        total = int(arcpy.GetCount_management(output_fc).getOutput(0))

 

        #Garbage cleanup

        del ic

        arcpy.Delete_management("in_memory/temp_boundary")

 

        arcpy.AddMessage(str(total) + " records in " + primary_secondary + " boundary")

        arcpy.AddMessage("Snapshot of " + str(in_boundary_lyr.value) + " loaded" + self.Time_Elapsed())

 

    #Check if boundaries layer has overlaps, which can create double counted pipe lengths

    def Intersect_Boundaries_Self(self, p):

 

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        bt_1 = 0

        bt_2 = 0

 

        arcpy.AddMessage("Checking boundary layers for overlap issues...");

        arcpy.Intersect_analysis("in_memory/boundaries",

                                 "in_memory/boundaries_self","ALL",0.0001,"INPUT")

 

        if arcpy.Exists("in_memory/boundaries_self"):

            bt_1 = int(arcpy.GetCount_management("in_memory/boundaries_self").getOutput(0))

 

        if in_boundary_lyr_2.value != None:

            arcpy.Intersect_analysis("in_memory/boundaries_2",

                                     "in_memory/boundaries_2_self","ALL",0.0001,"INPUT")

 

            bt_2 = int(arcpy.GetCount_management("in_memory/boundaries_2_self").getOutput(0))

 

    def List_Fields(self, fc):

        fields = arcpy.ListFields(fc)

        arcpy.AddMessage("Listing fields in " + str(fc))

 

        #Iterate through list of fields

        for field in fields:

            arcpy.AddMessage("Field: " + str(field.name))

 

    def Get_FieldNames(self, fc, skipfields = []):

        field_names = []

        fields = arcpy.ListFields(fc.replace("'",""))

        insert_field = False

 

        for field in fields:

            if len(skipfields) >= 1:

 

                insert_field = True

                for i in range(0, len(skipfields)):

                    if str(field.name) == skipfields[i]:

                        insert_field = False

                        break

 

                if insert_field == True:

                    field_names.append(str(field.name))

 

            else:

                field_names.append(str(field.name))

 

        return field_names

 

    def Get_FieldTypes(self, fc, skipfields = []):

        field_types = []

        fields = arcpy.ListFields(fc.replace("'",""))

        insert_field = False

 

        for field in fields:

            if len(skipfields) >= 1:

 

                insert_field = True

                for i in range(0, len(skipfields)):

                    if str(field.name) == skipfields[i]:

                        insert_field = False

                        break

 

                if insert_field == True:

                    field_types.append(str(field.type))

 

            else:

                field_types.append(str(field.type))

 

        return field_types

 

    def Get_ShapeType(self, fc):

        ret = ""

 

        if fc != None:

            temp_name = str(fc)

            temp_name = temp_name.replace("'","")

 

            desc = arcpy.Describe(temp_name)

            ret = str(desc.shapeType)

 

        return ret

 

    #Add boundary TEXT field mapping to field mappings object

    def Boundary_Join_Mappings(self, p, gasfacility_in_memory_fc):

 

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        boundary_fields = []

        boundary_fc = ""

 

        field_mappings = arcpy.FieldMappings()

        field_mappings.addTable("in_memory/"+ gasfacility_in_memory_fc)

 

        #arcpy.AddMessage(" ")

        #arcpy.AddMessage("Field mappings 1: " + str(field_mappings))

 

        boundary_fields = self.Get_FieldNames("in_memory/boundaries")

 

        if in_boundary_lyr_2.value != None:

             boundary_fields.extend(self.Get_FieldNames("in_memory/boundaries_2"))

 

        for i in range(0,len(boundary_fields)):

            fieldname = str(boundary_fields[i])

 

            if fieldname.find("_1") >= 0 or fieldname.find("_2") >= 0:

 

                boundary_fc = "boundaries"

                if fieldname.find("_2") >= 0:

                    boundary_fc = "boundaries_2"

 

                newMap = arcpy.FieldMap()

                newMap.addInputField("in_memory/" + boundary_fc, fieldname)

                newColumn = newMap.outputField

                newColumn.length = 50

                newColumn.name = fieldname

                newColumn.aliasName = fieldname

                newMap.outputField = newColumn

 

                field_mappings.addFieldMap(newMap)

 

                del newMap

                del newColumn

 

        #Fix field length

        temp_str = str(field_mappings.exportToString())

        if field_mappings:

            del field_mappings

 

        temp_str = temp_str.replace("false 0 Text","false 50 Text")

        temp_str = temp_str.replace("false 0 Double","false 8 Double")

 

        field_mappings = arcpy.FieldMappings()

        field_mappings.loadFromString(temp_str)

 

        return field_mappings

 

    def Translate_Field_Type(self, ftype):

        temp_type = str(ftype)

        if temp_type == "Integer":

            temp_type == "LONG"

        elif temp_type == "String":

            temp_type = "TEXT"

        elif temp_type == "SmallInteger":

            temp_type = "SHORT"

 

        return temp_type

 

    def Intersect_Points_To_Boundaries(self, p, input_fc):

 

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        in_boundary_lyr = p[self.in_boundary_lyr]

 

        total = 0

        secondary_boundary = ""

        boundary_intersect_fc = "boundaries" #includes secondary boundary intersect if required

        arcpy.AddMessage(" ")

 

        #Build seondary boundary intersection

        if in_boundary_lyr_2.value != None:

 

            boundary_intersect_fc = "boundaries_intersect"

 

            arcpy.AddMessage("Intersecting " + str(in_boundary_lyr.value) + " to " + str(in_boundary_lyr_2.value))

            arcpy.Intersect_analysis("in_memory/boundaries;in_memory/boundaries_2",

                                     "in_memory/" + boundary_intersect_fc,"ALL",0.0001,"INPUT")

 

        arcpy.AddMessage("Intersecting point layer(s) to boundaries" + self.Time_Elapsed())

 

        arcpy.Intersect_analysis("in_memory/" + boundary_intersect_fc + ";"+"in_memory/points",

                                 "in_memory/points_intersect","ALL",0.0001,"INPUT")

 

        if in_boundary_lyr_2.value != None:

            arcpy.Delete_management("in_memory/" + boundary_intersect_fc)

 

        if arcpy.Exists("in_memory/points_intersect"):

            total = arcpy.GetCount_management("in_memory/points_intersect").getOutput(0)

            arcpy.AddMessage(str(total) + " records in " + input_fc + " intersect" + self.Time_Elapsed())

 

        return total

 

    #Intersect gas facility to boundaries

    def Intersect_To_Boundaries(self, p, input_fc):

 

        total = 0

        count = 0

        boundary_count = 0

        boundary_mod = 1

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        in_boundary_lyr = p[self.in_boundary_lyr]

        intersect_clip_fc = input_fc + "_intersect"

 

        ic = None

        boundary_geometries = []

        boundary_fields = []

        boundary_rows = []

        results_fieldlist = ["SHAPE@"]

        pipe_fields = ["SHAPE@"]

 

        fc_type = "POLYLINE"

        if input_fc == "riser":

            fc_type = "POINT"

 

        secondary_boundary = ""

        boundary_intersect_fc = "boundaries" #includes secondary boundary intersect if required

        arcpy.AddMessage(" ")

 

        #Build seondary boundary intersection

        if in_boundary_lyr_2.value != None:

 

            boundary_intersect_fc = "boundaries_intersect"

            arcpy.AddMessage("Intersecting " + str(in_boundary_lyr.value) + " to " + str(in_boundary_lyr_2.value))

            arcpy.Intersect_analysis("in_memory/boundaries;"+"in_memory/boundaries_2",

                                     "in_memory/" + boundary_intersect_fc,"ALL",0.0001,"INPUT")

 

        #Clip gas facilities to boundary layer

        arcpy.AddMessage("Clipping " + input_fc + " to boundaries" + self.Time_Elapsed())

 

        #Create intersect + clip feature class

        sr = arcpy.Describe("in_memory/" + input_fc).spatialReference

        arcpy.CreateFeatureclass_management("in_memory", intersect_clip_fc, fc_type,"","ENABLED","ENABLED",sr)

 

        #Add pipe fields

        fields = arcpy.ListFields("in_memory/" + input_fc)

        for field in fields:

            if field.name != "OID" and field.name != "Shape" and field.name !="OBJECTID":

 

                results_fieldlist.append(str(field.name))

                pipe_fields.append(str(field.name))

 

                temp_type = self.Translate_Field_Type(str(field.type))

                arcpy.AddField_management("in_memory/" + intersect_clip_fc, str(field.name), temp_type)

 

        #Add boundary fields

        fields = arcpy.ListFields("in_memory/" + boundary_intersect_fc)

        for field in fields:

            if field.name != "OID" and field.name != "Shape" and field.name !="OBJECTID":

 

                results_fieldlist.append(str(field.name))

                boundary_fields.append(str(field.name))

 

                temp_type = self.Translate_Field_Type(str(field.type))

                arcpy.AddField_management("in_memory/" + intersect_clip_fc, str(field.name), temp_type)

 

        #Fetch list of boundary geometries and row data from boundary snapshot

        temp_fieldlist = ["SHAPE@"]

        temp_fieldlist.extend(list(boundary_fields))

        try:

            row = None

            cursor = None

            cursor = arcpy.da.SearchCursor("in_memory/" + boundary_intersect_fc, temp_fieldlist)

            for row in cursor:

 

                #Non-spatial row data

                temp_list = []

                for f in range(1, len(row)):

                    temp_list.append(row[f])

 

                boundary_rows.append(list(temp_list))

                boundary_geometries.append(row[0])

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        #Perform clip operations

        if len(boundary_geometries) >= 1:

 

            #Set modulus for status messages

            if len(boundary_geometries) >= 500:

                boundary_mod = 30

            elif len(boundary_geometries) >= 100:

                boundary_mod = 20

            elif len(boundary_geometries) >= 10:

                boundary_mod = 5

 

            ic = arcpy.da.InsertCursor("in_memory/" + intersect_clip_fc, results_fieldlist)

 

            sr = arcpy.Describe(in_boundary_lyr.value).spatialReference

            for i in range(len(boundary_geometries)):

                boundary_count = boundary_count + 1

 

                #Generate temporary clipped feature class

                arcpy.Clip_analysis("in_memory/" + input_fc, boundary_geometries[i], "in_memory/temp_facilities_clip")

                if arcpy.Exists("in_memory/temp_facilities_clip"):

                    try:

                        row = None

                        cursor = None

                        cursor = arcpy.da.SearchCursor("in_memory/temp_facilities_clip", pipe_fields)

                        for row in cursor:

 

                            temp_row = list(row)

                            temp_row.extend(boundary_rows[i])

                            ic.insertRow(temp_row)

 

                    except Exception, e:

                        raise Exception(str(e))

                    finally:

                        if row:

                            del row

                        if cursor:

                            del cursor

 

                    arcpy.Delete_management("in_memory/temp_facilities_clip")

 

                if boundary_count % boundary_mod == 0:

                    arcpy.AddMessage(str(boundary_count) + " out of " + str(len(boundary_geometries)) + \

                                     " boundaries processed" + self.Time_Elapsed())

 

            arcpy.AddMessage(str(len(boundary_geometries)) + " boundaries processed" + self.Time_Elapsed())

 

        ic = None

 

        if in_boundary_lyr_2.value != None:

            arcpy.Delete_management("in_memory/" + boundary_intersect_fc)

 

        arcpy.AddMessage(arcpy.GetCount_management("in_memory/" + intersect_clip_fc).getOutput(0) + \

                         " records in " + input_fc + " intersect" + self.Time_Elapsed())

 

        #Testing

##        arcpy.AddMessage("Copying in_memory/" + input_fc + " to C:/GISTesting for debug...")

##        loc = "C:/GISTesting/" + input_fc + "_intersect.shp"

##        if arcpy.Exists(loc):

##            arcpy.Delete_management(loc)

##        arcpy.CopyFeatures_management("in_memory/" + input_fc + "_intersect", loc)

 

        #Check if there is nothing in the intersection

        total = int(arcpy.GetCount_management("in_memory/" + intersect_clip_fc).getOutput(0))

 

        if total == 0:

            arcpy.AddMessage("No records found in " + input_fc + " to boundary layer intersection")

 

        return total

 

    def SQLite_Copy_Points_Intersect(self,p,c,Table_Name):

        global point_fields

        global point_intersect_fields

 

        count = 0

        point_intersect_fields = []

 

        exclude = ["Shape","OID","FID_points","FID_boundaries","FID_boundaries_intersect","FID_boundaries_2"]

 

        intersect_fields = self.Get_FieldNames("in_memory/"+ Table_Name, exclude)

        intersect_field_types = self.Get_FieldTypes("in_memory/" + Table_Name, exclude)

        point_intersect_fields = list(intersect_fields)

 

        #arcpy.AddMessage("sqlite fields: " + ",".join(intersect_fields))

        #arcpy.AddMessage("sqlite field types: " + ",".join(intersect_field_types))

 

        #arcpy.AddMessage("point intersect fields: " + ",".join(point_intersect_fields))

 

        #test 1: OID,Shape,FID_boundaries,BOUNDARYNAMEID_1,FID_points,DIVISION,LAYER_NAME,ADMINFLAG,COMMENTS

        #test 2: OID,Geometry,Integer,String,Integer,String,String,String,String

 

        #Create sqlite table

        sql = "CREATE TABLE " + Table_Name + " (\n"

        for i in range(0, len(intersect_fields)):

            if i > 0:

                sql = sql + ", \n"

 

            sql = sql + intersect_fields[i] + " "

 

            if intersect_field_types[i] == "String":

                sql = sql + "text"

            else:

                sql = sql + "integer"

 

        sql = sql + ")"

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Creating " + Table_Name + " SQLite table...")

        #arcpy.AddMessage(sql)

        c.execute(sql)

 

        #Create indexes

        for i in range(0, len(intersect_fields)):

            c.execute("CREATE INDEX P" + str(i) + " ON " + Table_Name + " (" + intersect_fields[i] + " ASC)")

 

        #Populate records

        count = 0

        try:

            row = None

            cursor = None

            cursor = arcpy.da.SearchCursor("in_memory/" + Table_Name, intersect_fields)

            for row in cursor:

                count = count + 1

 

                sql = "INSERT INTO " + Table_Name + " VALUES ("

                for i in range(0,len(intersect_fields)):

                    if i > 0:

                        sql = sql + ","

                    sql = sql + "'" + str(row[i]).replace("'","''") + "'"

                sql = sql + ")"

 

                c.execute(sql)

 

                if count > 0 and count % 50000 == 0:

                    arcpy.AddMessage(str(count) + "in_memory/" + Table_Name + " records copied to SQLite" + self.Time_Elapsed())

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        cursor = c.execute("SELECT COUNT(*) FROM " + Table_Name)

        for row in cursor:

            arcpy.AddMessage(str(row[0]) + " point intersect records copied to SQLite" + self.Time_Elapsed())

 

    def SQLite_Copy_Pipes_Intersect(self,p,c,Table_Name):

        global sqlite_fields

        global sqlite_types

        count = 0

        offset = 0

        offset1 =0

 

        arcpy.AddMessage("sqlite fields: " + ",".join(sqlite_fields))

        arcpy.AddMessage("sqlite field types: " + ",".join(sqlite_types))

 

        #Create sqlite table

        sql = "CREATE TABLE " + Table_Name + " (\n"

        for i in range(0,len(sqlite_fields)):

            if i > 0:

                sql = sql + ", \n"

            sql = sql + sqlite_fields[i] + " " + sqlite_types[i]

 

        sql = sql + ", \nNEW_LEN double"

        sql = sql + ")"

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Creating " + Table_Name + " SQLite table...")

        #arcpy.AddMessage(sql)     

        c.execute(sql)

 

        pipeCursor = c.execute('select * from '+ Table_Name)

        sql_table_fields = list(map(lambda x: x[0], pipeCursor.description))

        #arcpy.AddMessage(sql_table_fields)

 

        #Create indexes

        arcpy.AddMessage("Create indexes")

        for i in range(0, len(sqlite_fields)):           

            c.execute("CREATE INDEX C" + str(i) + " ON " + Table_Name + " (" + sqlite_fields[i] + " ASC)")

 

        temp_fields = list(sqlite_fields)

        temp_fields.append("SHAPE@LENGTH")

 

        #temp_fields.remove("SYSMOP")

        if "SYSMAOP" in temp_fields: temp_fields.remove("SYSMAOP")

        if "SYSMAOP" in sql_table_fields: sql_table_fields.remove("SYSMAOP")

       

 

 

        #Populate records

        count = 0

 

        try:

            row = None

            cursor = None

            arcpy.AddMessage("Search " +Table_Name)

            arcpy.AddMessage("temp fields: " + ",".join(temp_fields))

            cursor = arcpy.da.SearchCursor("in_memory/" + Table_Name, temp_fields)

            for row in cursor:

                count = count + 1

 

                sql = "INSERT INTO " + Table_Name+" ( "+",".join(sql_table_fields) + ") VALUES ("

                for i in range(0,len(temp_fields)):

                    if i > 0:

                        sql = sql + ","

                    sql = sql + "'" + str(row[i]).replace("'","''") + "'"

 

                sql = sql  + ")"

                #New shape length

                #sql = sql + ",'" + str(row[len(row)-1]) + "')"

 

                #arcpy.AddMessage("SQLite Insert sql: " + sql)

                c.execute(sql)

               

 

                #count = count + 1

                if count > 0 and count % 25000 == 0:

                    arcpy.AddMessage(str(count) + " in_memory " + Table_Name + " records copied to SQLite" + self.Time_Elapsed())

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

        if arcpy.Exists("in_memory/pipes_intersect"):

            arcpy.Delete_management("in_memory/pipes_intersect") #Garbage cleanup

       

        #Update recorded lengths based on comparing clipped to original shape length

        recalc_cols = ["MAIN","SERVICE","REC"]

        for r in recalc_cols:

            c.execute("UPDATE " + Table_Name + " SET " + r + "_LEN = " + r + "_LEN * (NEW_LEN/ORIG_LEN) WHERE " +

                      "NEW_LEN != 0 AND ORIG_LEN != 0 AND " + r + "_LEN != 0")

 

       

        

 

        #Add SYSMOP data from GasPressureSystem table

        try:

            offset = temp_fields.index("OPSSYSNAME")

        except ValueError:

            offset = -1

 

        if offset >= 0:

            arcpy.AddMessage("Add SYSMOP data to Gas Facilities Quantities")

            sql = "UPDATE " + Table_Name + " SET SYSMOP = " + \

                  "(SELECT SYSMOP FROM gaspressuresystem WHERE OPSSYSNAME = " + Table_Name + ".OPSSYSNAME)"

 

            arcpy.AddMessage(" ")

            arcpy.AddMessage("Fetching SYSMOP data from GasPressureSystem table")

            arcpy.AddMessage(sql)

            c.execute(sql)

 

 

        #Add YIELD data from gradeyield table       

        try:

            offset = temp_fields.index("GRADE")

            offset1 = temp_fields.index("SYSMOP")

        except ValueError:

            offset = -1

            offset1 = -1

 

        if offset >= 0 and offset1 >= 0:

            arcpy.AddMessage("Add YIELD data to Gas Facilities Quantities")

            sql = "UPDATE " + Table_Name + " SET YIELD = " + \

                    "(SELECT SYSMOP FROM gradeyield WHERE GRADE = " + Table_Name + ".GRADE)"

 

            arcpy.AddMessage(" ")

            arcpy.AddMessage("Fetching YIELD data from GradeYield table")

            arcpy.AddMessage(sql)

            c.execute(sql)

 

 

        #Add OUTSIDE_DIAMETER data to Gas Facilities Quantities

 

        try:

            offset = temp_fields.index("OUTSIDE_DIAMETER")

        except ValueError:

            offset = -1

 

        if offset >= 0:

            arcpy.AddMessage("Add OUTSIDE_DIAMETER data to Gas Facilities Quantities")

 

            nominal_diameters = []

            outside_diameters = []

            sql = "SELECT DISTINCT nominal, outside FROM outside_diameter_info"

            arcpy.AddMessage(" ")

            arcpy.AddMessage("Fetching OUTSIDE_DIAMETER data from outside_diameter_info table")

            arcpy.AddMessage(sql)

            cursor = c.execute(sql)

            for row in cursor:

                nominal_diameters.append(float(row[0]))

                outside_diameters.append(float(row[1]))

 

            for f in range(0, len(nominal_diameters)):

                sql = "UPDATE " + Table_Name + " SET OUTSIDE_DIAMETER = " + str(outside_diameters[f]) + " WHERE DIAMETER = " + str(nominal_diameters[f])

                cursor = c.execute(sql)

 

            #OUTSIDE_DIAMETER QC check

            sql = "SELECT COUNT(*), DIAMETER, OUTSIDE_DIAMETER FROM " + Table_Name + " GROUP BY DIAMETER, OUTSIDE_DIAMETER ORDER BY DIAMETER"

 

 

            cursor = c.execute(sql)

            for row in cursor:

                arcpy.AddMessage("diameter: " + str(row[1]) + ", outside diameter: " + str(row[2]) + ", count: " + str(row[0]))

 

 

        offset1 = -1

        offset2 = -1

        offset3 = -1

        offset4 = -1

        try:

            offset1 = temp_fields.index("OUTSIDE_DIAMETER")

            offset2 = temp_fields.index("YIELD")

            offset3 = temp_fields.index("WALLTHICKNESS")

            offset4 = temp_fields.index("SYSMOP")

        except ValueError:

            offset1 = -1

            offset2 = -1

            offset3 = -1

            offset4 = -1

 

        #Calculate SMYS

        if offset1 >= 0 and offset2 >= 0 and offset3 >= 0 and offset4 >= 0:

            arcpy.AddMessage("Calculating SMYS on " + Table_Name + self.Time_Elapsed())

            sql = "UPDATE " + Table_Name + " SET SMYS = ((100)*(SYSMOP)*(OUTSIDE_DIAMETER)) / ((2)*(YIELD)*(WALLTHICKNESS)) WHERE WALLTHICKNESS IS NOT NULL AND WALLTHICKNESS>0 AND YIELD IS NOT NULL AND YIELD>0"

            arcpy.AddMessage(sql)

            cursor = c.execute(sql)         

 

 

        offset1 = -1

        offset2 = -1

        #Add SYSMAOP data from GasPressureSystem table

        try:

            offset1 = temp_fields.index("OPSSYSNAME")

            offset2 = sqlite_fields.index("SYSMAOP")

        except ValueError:

            offset1 = -1

            offset2 = -1

 

        if offset1 >= 0 and offset2 >= 0:

            sql = "UPDATE " + Table_Name + " SET SYSMAOP = " + \

                  "(SELECT SYSMAOP FROM gaspressuresystem WHERE OPSSYSNAME = " + Table_Name + ".OPSSYSNAME)"

 

            arcpy.AddMessage(" ")

            arcpy.AddMessage("Fetching SYSMAOP data from GasPressureSystem table")

            arcpy.AddMessage(sql)

            c.execute(sql)

 

        cursor = c.execute("SELECT COUNT(*) FROM " + Table_Name)

        for row in cursor:

            arcpy.AddMessage(str(row[0]) + " pipe intersect records copied to SQLite" + self.Time_Elapsed())

 

    def Copy_To_SQLite_Simple(self, toc_fc, sqlite_table_name, t_cols, t_coltypes, c):

 

        cols = list(t_cols)

        coltypes = list(t_coltypes)

        sqlite_cols = list(cols)

        row = None

        cursor = None

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Copying " + toc_fc + " to " + sqlite_table_name + " SQLite table" + self.Time_Elapsed())

 

        sql = "CREATE TABLE " + sqlite_table_name + " (\n"

        for i in range(0, len(sqlite_cols)):

            if i > 0:

                sql = sql + ", "

            sql = sql + sqlite_cols[i] + " "

 

            if coltypes[i] == "TEXT":

                sql = sql + "text"

            elif coltypes[i] == "LONG":

                sql = sql + "integer"

            else:

                sql = sql + "real"

        sql = sql + ")"

 

        arcpy.AddMessage("SQLite create table: " + sql)

        c.execute(sql)

 

        #Populate records

        count = 0

        try:

            cursor = arcpy.da.SearchCursor(toc_fc, cols)

            for row in cursor:

                count = count + 1

                sql = "INSERT INTO " + sqlite_table_name + " VALUES ("

 

                for i in range(0,len(cols)):

                    if i > 0:

                        sql = sql + ","

 

                    tempval = str(row[i])

                    sql = sql + "'" + str(tempval).replace("'","''") + "'"

 

                sql = sql + ")"

                c.execute(sql)

 

                if count > 0 and count % 50000 == 0:

                    arcpy.AddMessage(str(count) + " records copied to SQLite" + self.Time_Elapsed())

 

            arcpy.AddMessage(str(count) + " records copied to SQLite" + self.Time_Elapsed())

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        #Create indexes

        for i in range(0, len(sqlite_cols)):

            c.execute("CREATE INDEX " + sqlite_table_name + str(i) + " ON " + sqlite_table_name + " (" + sqlite_cols[i] + " ASC)")

 

    def Excel_FilePath(self, p):

        global user_division

 

        now = dt.datetime.now()

 

        hh = str(now.hour)

        m = str(now.minute)

        ss = str(now.second)

 

        if len(hh) == 1:

            hh = "0" + hh

        if len(m) == 1:

            m = "0" + m

        if len(ss) == 1:

            ss = "0" + ss

       

        #out_directory = p[self.out_directory]

        out_directory = user_directory

        arcpy.AddMessage(out_directory)

        tstamp = str(now.year) + "-" + str(now.month) + "-" + str(now.day) + "-" + hh + m + ss

 

       # out_directory_str = str(out_directory.value)

        out_directory_str = out_directory

 

        #Add last character to output directory

        if out_directory_str.find("/") >= 0 and out_directory_str.endswith("/") == False:

            out_directory_str = out_directory_str + "/"

 

        if out_directory_str.find("\\") >= 0 and out_directory_str.endswith("\\") == False:

            out_directory_str = out_directory_str + "\\"

 

 

        #Excel file path

        fpath = out_directory_str + "Quantities Report " + \

                user_division + " " + \

                os.environ.get("USERNAME").upper() + " " + \

                tstamp + ".xlsx"

 

        return fpath

 

    def Points_Intersect_To_Excel(self, p, c, workbook = None):

 

        global point_fields

        global point_intersect_fields

 

        in_boundary_alias_cols = p[self.in_boundary_alias_cols]

        in_boundary_alias_cols_2 = p[self.in_boundary_alias_cols_2]

 

        in_boundary_alias_cols = str(in_boundary_alias_cols.value)

        in_boundary_alias_cols_2 = str(in_boundary_alias_cols_2.value)

 

        alias_cols = in_boundary_alias_cols.split(",")

        alias_cols_2 = in_boundary_alias_cols_2.split(",")

 

        boundary_aliases = []

        if len(alias_cols) >= 1:

            boundary_aliases.extend(list(alias_cols))

        if len(alias_cols_2) >= 1:

            boundary_aliases.extend(list(alias_cols_2))

 

        total_sum = 0

 

        #arcpy.AddMessage("Boundary aliases: " + ",".join(boundary_aliases))

        #arcpy.AddMessage("Point intersect fields: " + ",".join(point_intersect_fields))

 

        worksheet = workbook.add_worksheet("Point Quantities Report")

        bold = workbook.add_format({'bold': True})

        count_format = workbook.add_format({'num_format': '0'})

 

        #Generate grouped SQL query and excel column header

        count = 0

        sql = "SELECT "

        col_list = "" #comma delimited string for order and group by SQL

 

        for i in range(0, len(point_intersect_fields)):

 

            if count == 0:

                col_list = col_list + point_intersect_fields[i]

            else:

                col_list = col_list + ", " + point_intersect_fields[i]

 

            #Column is a boundary alias

            if i < len(boundary_aliases):

                worksheet.write(0, count, boundary_aliases[i],bold) #Row 1

            else:

                worksheet.write(0, count, point_intersect_fields[i],bold) #Row 1

 

            worksheet.set_column(count, count, len(point_intersect_fields[i])+1) #Row 1

            count = count + 1

 

        #Add count column to header

        worksheet.write(0, count, "Count", bold)

        worksheet.set_column(count,count,12)

 

        sql = sql + col_list

        if len(col_list) >= 1:

            sql = sql + ","

 

        sql = sql + " COUNT(*) "

        sql = sql + "FROM points_intersect GROUP BY "

        sql = sql + col_list + " ORDER BY " + col_list

 

        arcpy.AddMessage("Saving results to Excel workbook..." + self.Time_Elapsed())

        cursor = c.execute(sql)

 

        count = 1 #start inserting from row 2 in excel

        for row in cursor:

 

            total_sum = total_sum + float(row[len(row)-1])

 

            for i in range(0, len(row)):

                if i >= (len(row)-1):

                    worksheet.write(count, i, int(row[i]), count_format)

                else:

                    worksheet.write(count, i, str(row[i]))

 

            count = count + 1

 

        #Write total pipe length sum

        column_count = len(col_list.split(","))

        worksheet.write(count, column_count, total_sum, count_format)

 

        arcpy.AddMessage(str(count) + " rows added to Excel worksheet" + self.Time_Elapsed())

 

    def Pipes_Intersect_To_Excel(self, p, c, workbook):

        global sqlite_fields

        global sqlite_types

 

        offset = 0

        main_sum = 0.0

        service_sum = 0.0

        ab_main_sum = 0.0

        ab_service_sum = 0.0

        total_sum = 0.0

        ab_total_sum = 0.0

        shape_suffix = ""

 

        in_facility_layers = str(p[self.in_facility_layers].value)

        in_length_type = str(p[self.in_length_type].value)

 

        if in_length_type == "Shape Length":

            shape_suffix = "Shape "

 

        worksheet = workbook.add_worksheet("Pipe Quantities Report")

        bold = workbook.add_format({'bold': True})

        length_format = workbook.add_format({'num_format': '0.000'})

 

        #Create workbook header

        sql = "SELECT "

        col_list = "" #comma delimited string for order and group by SQL

        ignore_cols = ["MAIN_LEN","SERVICE_LEN","AB_MAIN_LEN","AB_SERVICE_LEN","ORIG_LEN","NEW_LEN","REC_LEN"]

 

        arcpy.AddMessage("SQLite columns (Pipes_Intersect_To_Excel): " + ",".join(sqlite_fields))

 

        #Generate grouped SQL query and excel column header

        count = 0

        for i in range(0, len(sqlite_fields)):

            f = sqlite_fields[i]

 

            try:

                offset = ignore_cols.index(f)

            except ValueError:

                offset = -1

 

            if offset == -1:

                sql = sql + f + ","

 

                if count == 0:

                    col_list = col_list + f

                else:

                    col_list = col_list + ", " + f

 

                worksheet.set_column(count, count, len(sqlite_aliases[i])+1) #Row 1

                worksheet.write(0, count, sqlite_aliases[i],bold) #Row 1

                count = count + 1

 

        #Add sum columns and to header

        if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

 

            #arcpy.AddMessage("test abandoned")

 

            worksheet.write(0, count, "Main Length", bold)

            worksheet.write(0, count+1, "Service Length", bold)

            worksheet.write(0, count+2, "Abandoned Main Length", bold)

            worksheet.write(0, count+3, "Abandoned Service Length", bold)

            worksheet.write(0, count+4, "Total " + shape_suffix + "Length", bold)

            worksheet.write(0, count+5, "Total Abandoned " + shape_suffix + "Length", bold)

 

            worksheet.set_column(count,count,12)

            worksheet.set_column(count+1,count+1,12)

            worksheet.set_column(count+2,count+2,12)

            worksheet.set_column(count+3,count+3,12)

            worksheet.set_column(count+4,count+4,12)

            worksheet.set_column(count+5,count+5,12)

 

            #sql = sql + "SUM(MAIN_LEN), SUM(SERVICE_LEN), SUM(AB_MAIN_LEN), SUM(AB_SERVICE_LEN), SUM(REC_LEN) "

 

            sql = sql + "SUM(MAIN_LEN), SUM(SERVICE_LEN), SUM(AB_MAIN_LEN), SUM(AB_SERVICE_LEN), "

            sql = sql + "SUM(MAIN_LEN) + SUM(SERVICE_LEN), SUM(AB_MAIN_LEN) + SUM(AB_SERVICE_LEN) "

 

            sql = sql + "FROM pipes_intersect GROUP BY "

            sql = sql + col_list + " ORDER BY " + col_list

 

        else:

 

            worksheet.write(0, count, "Main Length", bold)

            worksheet.write(0, count+1, "Service Length", bold)

            worksheet.write(0, count+2, "Total " + shape_suffix + "Length", bold)

 

            worksheet.set_column(count,count,12)

            worksheet.set_column(count+1,count+1,13)

            worksheet.set_column(count+2,count+2,12)

 

            sql = sql + "SUM(MAIN_LEN), SUM(SERVICE_LEN), SUM(REC_LEN) "

            sql = sql + "FROM pipes_intersect GROUP BY "

            sql = sql + col_list + " ORDER BY " + col_list

 

        arcpy.AddMessage("Grouped query: " + sql)

 

        arcpy.AddMessage("Saving results to Excel workbook..." + self.Time_Elapsed())

        cursor = c.execute(sql)

 

        count = 1 #start inserting from row 2 in excel

        for row in cursor:

 

            temp_line = ""

 

##            main_sum = main_sum + float(row[len(row)-3])

##            service_sum = service_sum + float(row[len(row)-2])

##            total_sum = total_sum + float(row[len(row)-1])

 

            if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

 

                main_sum = main_sum + float(row[len(row)-6])

                service_sum = service_sum + float(row[len(row)-5])

                ab_main_sum = ab_main_sum + float(row[len(row)-4])

                ab_service_sum = ab_service_sum + float(row[len(row)-3])

 

                #total_sum = total_sum + float(row[len(row)-1])

                total_sum = total_sum + float(row[len(row)-6]) + float(row[len(row)-5])

                ab_total_sum = ab_total_sum + float(row[len(row)-4]) + float(row[len(row)-3])

 

                for i in range(0, len(row)):

 

                    #last 6 columns formatted as double with 4 decimal places

                    if i >= (len(row)-6):

                        worksheet.write(count, i, float(row[i]), length_format)

                    else:

                        worksheet.write(count, i, str(row[i]))

 

            else:

 

                main_sum = main_sum + float(row[len(row)-3])

                service_sum = service_sum + float(row[len(row)-2])

 

                total_sum = total_sum + float(row[len(row)-1])

 

                for i in range(0, len(row)):

 

                    temp_val = self.Clean_String(str(row[i]))

 

                    #last 3 columns formatted as double with 4 decimal places

                    if i >= (len(row)-3):

                        if len(temp_val) == 0:

                            temp_val = "0"

 

                        worksheet.write(count, i, float(temp_val), length_format)

                    else:

                        worksheet.write(count, i, temp_val)

 

                    #CSV test here:

                    temp_line = temp_line + "'" + temp_val + "'|"

 

 

            #arcpy.AddMessage(temp_line)

 

            count = count + 1

 

        #Write total pipe length sum

        column_count = len(col_list.split(","))

 

        if in_facility_layers.find("Abandoned Gas Pipe") >= 0:

 

            worksheet.write(count, column_count, main_sum, length_format)

            worksheet.write(count, column_count+1, service_sum, length_format)

            worksheet.write(count, column_count+2, ab_main_sum, length_format)

            worksheet.write(count, column_count+3, ab_service_sum, length_format)

            worksheet.write(count, column_count+4, total_sum, length_format)

            worksheet.write(count, column_count+5, ab_total_sum, length_format)

 

        else:

 

            worksheet.write(count, column_count, main_sum, length_format)

            worksheet.write(count, column_count+1, service_sum, length_format)

            worksheet.write(count, column_count+2, total_sum, length_format)

 

        arcpy.AddMessage(str(count) + " rows added to Excel worksheet" + self.Time_Elapsed())

 

    def Clean_String(self, tstr):

 

        temp_val = str(tstr)

        temp_val = temp_val.lstrip().rstrip()

        if len(temp_val) >= 1:

            temp_val = self.remove_ascii_non_printable(temp_val)

        if len(temp_val) >= 1:

            temp_val = self.remove_unicode_non_printable(temp_val)

        if len(temp_val) >= 1:

            temp_val = self.remove_non_ascii(temp_val)

 

        return temp_val

 

    def remove_ascii_non_printable(self, str):

        return ''.join([ch for ch in str if ord(ch) > 31 and ord(ch) < 126 or ord(ch) == 9])

 

    def remove_unicode_non_printable(self, str):

        return ''.join([ch for ch in str if ord(ch) > 31 or ord(ch) == 9])

 

    def remove_non_ascii(self, string):

        stripped = (ch for ch in string if 0 < ord(ch) < 127)

        return ''.join(stripped)

 

    def Boundary_Errors_To_Excel(self, p, workbook, primary_secondary = "primary"):

 

        count = 1

 

        if primary_secondary == "primary":

            in_boundary_lyr = p[self.in_boundary_lyr]

            in_boundary_cols = p[self.in_boundary_cols]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols]

            fc = "boundaries_self"

 

        else:

            in_boundary_lyr = p[self.in_boundary_lyr_2]

            in_boundary_cols = p[self.in_boundary_cols_2]

            in_boundary_alias_cols = p[self.in_boundary_alias_cols_2]

            fc = "boundaries_self_2"

 

        if in_boundary_cols.value != None:

 

            boundary_cols = str(in_boundary_cols.value).split(",")

            if len(boundary_cols) >= 1 and arcpy.Exists(fc) == True:

 

                arcpy.AddMessage(" ")

                arcpy.AddMessage("Checking for " + primary_secondary + " boundary polygon overlap issues" + self.Time_Elapsed())

 

                #Check counts

                total = int(arcpy.GetCount_management(fc).getOutput(0))

                if total > 0:

 

                    #Add _2 suffix to secondary boundarys

                    if fc == "boundaries_self_2":

                        for i in range(0, len(boundary_cols)):

                            boundary_cols[i] = boundary_cols[i] + "_2"

                    else:

                        for i in range(0, len(boundary_cols)):

                            boundary_cols[i] = boundary_cols[i] + "_1"

 

                    #Create worksheet

                    worksheet = workbook.add_worksheet(str(in_boundary_lyr.value).upper() + " Overlaps")

                    bold = workbook.add_format({'bold': True})

 

                    #Add worksheet column titles

                    alias_cols = str(in_boundary_alias_cols.value).split(",")

                    for i in range(0, len(alias_cols)):

                        worksheet.write(0, i, alias_cols[i],bold)

                        worksheet.set_column(i,i,len(alias_cols[i]))

 

                    #Write data

                    try:

                        row = None

                        cursor = None

 

                        cursor = arcpy.da.SearchCursor(fc, boundary_cols)

                        for row in cursor:

                            for i in range(0, len(row)):

 

                                #worksheet.write(count, i, row[i])

                                worksheet.write(count, i, self.Clean_String(str(row[i])))

 

                            count = count + 1

 

                    except Exception, e:

                        raise Exception(str(e))

                    finally:

                        if row:

                            del row

                        if cursor:

                            del cursor

 

                    arcpy.AddMessage("Boundary overlap issues logged in Excel worksheet" + self.Time_Elapsed())

 

    def Create_Premise_Snapshot(self, c):

 

        arcpy.AddMessage(" ")

        arcpy.AddMessage("Taking snapshot of premise table" + self.Time_Elapsed())

        count = 0

 

        c.execute("CREATE TABLE premise (RISERSWGUID text, PREMISEID text, SAPPREMISEID text)")

        c.execute("CREATE INDEX D1 ON premise (RISERSWGUID ASC)")

        c.execute("CREATE INDEX D2 ON premise (PREMISEID ASC)")

 

        try:

            row = None

            cursor = None

            sap_premise_id = None

            dict_sapdata = {}

            cursor_sap = arcpy.da.SearchCursor("SAPDATA", ["LEGACYPREMISEID","SAPPREMISEID"])

            for row in cursor_sap:

                dict_sapdata[row[0]] = row[1]

 

            cursor = arcpy.da.SearchCursor("Premise", ["RISERSWGUID","PREMISEID"])

            for row in cursor:

                sap_premise_id = None

                if row[1] in dict_sapdata:

                    sap_premise_id = dict_sapdata[row[1]]

 

                c.execute("INSERT INTO premise VALUES ('" + str(row[0]) + "','" + str(row[1]) + "','"+str(sap_premise_id)+ "')")

                count = count + 1

 

                if count > 0 and count % 50000 == 0:

                    arcpy.AddMessage(str(count) + " premise records copied" + self.Time_Elapsed())

 

        except Exception, e:

            raise Exception(str(e))

        finally:

            if row:

                del row

            if cursor:

                del cursor

 

        cursor = c.execute("SELECT COUNT(*) FROM premise")

        for row in cursor:

            arcpy.AddMessage(str(row[0]) + " premise records copied" + self.Time_Elapsed())

 

        #arcpy.AddMessage("Snapshot of premise loaded" + self.Time_Elapsed())

 

    def Load_Boundary_Layers(self, p):

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

 

        #Boundary layer(s) snapshot

        self.Create_Boundary_FeatureClass(p)

        if in_boundary_lyr_2.value != None:

            self.Create_Boundary_FeatureClass(p, "secondary")

 

    def Delete_Boundary_Layers(self):

        try:

            if arcpy.Exists("in_memory/pipes"):

                arcpy.Delete_management("in_memory/pipes")

 

            if arcpy.Exists("in_memory/points"):

                arcpy.Delete_management("in_memory/points")

 

            if arcpy.Exists("in_memory/boundaries"):

                arcpy.Delete_management("in_memory/boundaries")

 

            if arcpy.Exists("in_memory/boundaries_2"):

                arcpy.Delete_management("in_memory/boundaries_2")

        except:

            pass

 

    def Summarize_Row(self, p, offset, workbook, worksheet):

        bold = workbook.add_format({'bold': True})

        worksheet.write(offset+1, 0, str(p[offset].name),bold)

        worksheet.write(offset+1, 1, str(p[offset].value).replace("'",""))

 

    def Summarize_Workbook(self, p, workbook):

 

        worksheet = workbook.add_worksheet("Summary")

        bold = workbook.add_format({'bold': True})

 

        worksheet.write(0, 0, "Field Name",bold)

        worksheet.write(0, 1, "Field Value",bold)

        worksheet.set_column(0,0,120)

        worksheet.set_column(1,1,50)

 

        for i in range(0, len(p)):

            self.Summarize_Row(p, i, workbook, worksheet) #Testing

 

        #worksheet.write(len(p)+1, 0, "ArcPy Tool Messages",bold)

        #worksheet.write(len(p)+1, 1, str(arcpy.GetMessages()))

 

 

    def get_config_option(self, config, section, option):

   

        try:

            configValue = config.get(section, option)

        except Exception as e:

            raise e

       

        return configValue

 

    def load_settings(self, p, file_name):

       

##        in_retrieve_prefs = 0                         IGNORE

##        in_facility_layers = 1          GPLayer                                Main, Service, or Point Layer(s) ...

##        in_boundary_lyr = 2                          ValueList              Primary Boundary Layer from ArcMap Table of Contents

##        in_boundary_cols = 3                        DEFile                    Primary Boundary Layer: Query Text File

##        in_boundary_alias_cols = 4            GPString               Primary Boundary Layer: List of fields for report, comma delimited

##        in_boundary_filter = 5      GPString               Secondary Boundary Layer from ArcMap Table of Contents...       

##        in_boundary_lyr_2 = 6                     DEFile                    Secondary Boundary Layer: Query Text File

##        in_boundary_cols_2 = 7   GPString               Secondary Boundary Layer: List of fields for report, comma delimited

##        in_boundary_alias_cols_2 = 8       GPString               Secondary Boundary Layer: List of field aliases for report header, comma delimited

##        in_boundary_filter_2 = 9 ValueList

##        in_pipe_cols = 10                               GPString               Main/Service column(s) for report (Division, Main Length, Service Length, and Total Length are included by default)

##        in_point_cols = 11                              GPString               Point column(s) for report (Division, Count, and Layer Name are included by default)

##        in_pipe_materials = 12     GPString               Material...

##        in_pipe_types = 13                            ValueList

##        in_size_from = 14                               GPDouble            Size Range: Minimum

##        in_size_to = 15                    GPDouble            Size Range: Maximum

##        in_date_from = 16                             GPDate                 Install Date Range: Minimum

##        in_date_to = 17                   GPDate                 Install Date Range: Maximum

##        in_year_list = 18                 GPString               List of Install Years, Comma Delimited

##        in_length_type = 19                          GPString               Calculate Pipe Recorded Length or Shape Length

##        out_file_name = 20            GPString        Output File Name

##        out_save_as = 21                                IGNORE

       

        config = ConfigParser.SafeConfigParser()

        config.optionxform = str

        app_path = os.path.dirname(file_name)

        config.read(os.path.join(app_path,file_name))

        config_section = "Preferences"

        saved_items = config.items(config_section)

       

        #try:

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_facility_layers'), 'in_facility_layers', 0)  

        p[self.in_facility_layers].value = self.get_config_option(config, config_section, 'in_facility_layers')

        self.Refresh_Point_Fields(p)

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_lyr'), 'in_boundary_lyr', 0)

        p[self.in_boundary_lyr].value = self.get_config_option(config, config_section, 'in_boundary_lyr')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_cols'), 'in_boundary_cols', 0)

        p[self.in_boundary_cols].value = self.get_config_option(config, config_section, 'in_boundary_cols')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_alias_cols'), 'in_boundary_alias_cols', 0)

        p[self.in_boundary_alias_cols].value = self.get_config_option(config, config_section, 'in_boundary_alias_cols')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_filter'), 'in_boundary_filter', 0)

        p[self.in_boundary_filter].value = self.get_config_option(config, config_section, 'in_boundary_filter')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_lyr_2'), 'in_boundary_lyr_2', 0)

        p[self.in_boundary_lyr_2].value = self.get_config_option(config, config_section, 'in_boundary_lyr_2')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_cols_2'), 'in_boundary_cols_2', 0)

        p[self.in_boundary_cols_2].value = self.get_config_option(config, config_section, 'in_boundary_cols_2')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_alias_cols_2'), 'in_boundary_alias_cols_2', 0)

        p[self.in_boundary_alias_cols_2].value = self.get_config_option(config, config_section, 'in_boundary_alias_cols_2')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_boundary_filter_2'), 'in_boundary_filter_2', 0)

        p[self.in_boundary_filter_2].value = self.get_config_option(config, config_section, 'in_boundary_filter_2')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_pipe_cols'), 'in_pipe_cols', 0)

        p[self.in_pipe_cols].value = self.get_config_option(config, config_section, 'in_pipe_cols')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_point_cols'), 'in_point_cols', 0)

        p[self.in_point_cols].value = self.get_config_option(config, config_section, 'in_point_cols')

        #MessageBox(None, self.get_config_option(config, config_section, 'in_pipe_materials'), 'in_pipe_materials', 0)

        p[self.in_pipe_materials].value = self.get_config_option(config, config_section, 'in_pipe_materials')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_pipe_types'), 'in_pipe_types', 0)

        p[self.in_pipe_types].value = self.get_config_option(config, config_section, 'in_pipe_types')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_size_from'), 'in_size_from', 0)

        p[self.in_size_from].value = self.get_config_option(config, config_section, 'in_size_from')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_size_to'), 'in_size_to', 0)

        p[self.in_size_to].value = self.get_config_option(config, config_section, 'in_size_to')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_date_from'), 'in_date_from', 0)

        p[self.in_date_from].value = self.get_config_option(config, config_section, 'in_date_from')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_date_to'), 'in_date_to', 0)

        p[self.in_date_to].value = self.get_config_option(config, config_section, 'in_date_to')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_year_list'), 'in_year_list', 0)

        p[self.in_year_list].value = self.get_config_option(config, config_section, 'in_year_list')

        ##MessageBox(None, self.get_config_option(config, config_section, 'in_length_type'), 'in_length_type', 0)

        p[self.in_length_type].value = self.get_config_option(config, config_section, 'in_length_type')

        #p[self.in_boundary_lyr].value = self.get_config_option(config, config_section, 'in_boundary_lyr')          

        #except Exception as ex:   

            #MessageBox(None, ex.message, 'load_settings', 0)

 

       

    def save_settings(self, p, file_name):

##        in_retrieve_prefs = 0                         IGNORE

##        in_facility_layers = 1          GPLayer                                Main, Service, or Point Layer(s) ...

##        in_boundary_lyr = 2                          ValueList              Primary Boundary Layer from ArcMap Table of Contents

##        in_boundary_cols = 3                        DEFile                    Primary Boundary Layer: Query Text File

##        in_boundary_alias_cols = 4            GPString               Primary Boundary Layer: List of fields for report, comma delimited

##        in_boundary_filter = 5      GPString               Secondary Boundary Layer from ArcMap Table of Contents...       

##        in_boundary_lyr_2 = 6                     DEFile                    Secondary Boundary Layer: Query Text File

##        in_boundary_cols_2 = 7   GPString               Secondary Boundary Layer: List of fields for report, comma delimited

##        in_boundary_alias_cols_2 = 8       GPString               Secondary Boundary Layer: List of field aliases for report header, comma delimited

##        in_boundary_filter_2 = 9 ValueList

##        in_pipe_cols = 10                               GPString               Main/Service column(s) for report (Division, Main Length, Service Length, and Total Length are included by default)

##        in_point_cols = 11                              GPString               Point column(s) for report (Division, Count, and Layer Name are included by default)

##        in_pipe_materials = 12     GPString               Material...

##        in_pipe_types = 13                            ValueList

##        in_size_from = 14                               GPDouble            Size Range: Minimum

##        in_size_to = 15                    GPDouble            Size Range: Maximum

##        in_date_from = 16                             GPDate                 Install Date Range: Minimum

##        in_date_to = 17                   GPDate                 Install Date Range: Maximum

##        in_year_list = 18                 GPString               List of Install Years, Comma Delimited

##        in_length_type = 19                          GPString               Calculate Pipe Recorded Length or Shape Length

##        out_file_name = 20            GPString        Output File Name

##        out_save_as = 21                                IGNORE

 

        config = ConfigParser.SafeConfigParser()

        config.optionxform = str

 

        #Required configuration settings

        config_section = "Preferences"

       

        # When adding sections or items, add them in the reverse order of

        # how you want them to be displayed in the actual file.

        config.add_section(config_section)

 

        #Cannot iterate -- name property of parameter returns displayname property value

##        for i in range(1, 22):

##            try:

##                MessageBox(None, 'datatype:' + str(p[i].datatype), 'save_settings', 0)

##                if str(p[i].datatype).upper() == 'STRING':

##                    config_option = str(p[i].name)

##                    MessageBox(None, 'name:' + str(p[i].name), 'save_settings', 0)

##                    config_value = str(p[i].value)

##                    config.set(config_section,config_option,config_value)

##                    MessageBox(None, 'Configuration set', 'save_settings', 0)

##            except Exception as ex:

##                MessageBox(None, ex.message, 'save_settings', 0)

 

        #try:

        config_value = str(p[self.in_facility_layers].value)

        config_option = 'in_facility_layers'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_lyr].value)

        config_option = 'in_boundary_lyr'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_cols].value)

        config_option = 'in_boundary_cols'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_alias_cols].value)

        config_option = 'in_boundary_alias_cols'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_filter].value)

        config_option = 'in_boundary_filter'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_lyr_2].value)

        config_option = 'in_boundary_lyr_2'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_cols_2].value)

        config_option = 'in_boundary_cols_2'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_alias_cols_2].value)

        config_option = 'in_boundary_alias_cols_2'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_boundary_filter_2].value)

        config_option = 'in_boundary_filter_2'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_pipe_cols].value)

        config_option = 'in_pipe_cols'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_point_cols].value)

        config_option = 'in_point_cols'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_pipe_materials].value)

        config_option = 'in_pipe_materials'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_pipe_types].value)

        config_option = 'in_pipe_types'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_size_from].value)

        config_option = 'in_size_from'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_size_to].value)

        config_option = 'in_size_to'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_date_from].value)

        config_option = 'in_date_from'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_size_to].value)

        config_option = 'in_size_to'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_date_to].value)

        config_option = 'in_date_to'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_year_list].value)

        config_option = 'in_year_list'

        config.set(config_section,config_option,config_value)

        config_value = str(p[self.in_length_type].value)

        config_option = 'in_length_type'

        config.set(config_section,config_option,config_value)

        #except Exception as ex:

            #MessageBox(None, ex.message, 'save_settings', 0)

       

        # Writing our configuration file to 'example.cfg'

        with open(file_name, 'wb') as config_file:

            config.write(config_file)

 

        #MessageBox(None, file_name, 'save_settings', 0)

       

 

    def get_config_option(self, config, section, option):

        try:

            config_value = config.get(section, option)

            if config_value == 'None':

                config_value = ''

        except Exception as e:

            raise e

       

        return config_value

 

 

    def execute(self, p, messages):

 

        global start_time

        global sqlite_types

        global sqlite_fields

        global sqlite_aliases

 

        arcpy.ClearWorkspaceCache_management()

        arcpy.Delete_management("in_memory")

        start_time = dt.datetime.now()

 

        #in_premise_count = p[self.in_premise_count]

 

        in_boundary_lyr_2 = p[self.in_boundary_lyr_2]

        in_facility_layers = str(p[self.in_facility_layers].value).split(";")

        in_point_cols_str = str(p[self.in_point_cols].value)

 

        #premise_count = str(in_premise_count.value)

        pipe_intersect_total = 0

        point_intersect_total = 0

 

        pipe_layer_count = 0

        point_layer_count = 0

 

        arcpy.Delete_management("in_memory")

        GFQRsqliteDB_Path = r'C:\Temp\GFQRsqliteDataFiles'

        # GFQRsqliteDB_name = 'GFQRsqlite_{}.db'.format(datetime.datetime.now().strftime('%Y%m%d%H%M%S'))

        # if os.path.exists(GFQRsqliteDB_Path) == False:

        #     os.mkdir(GFQRsqliteDB_Path)

     

        # GFQRsqliteDB = os.path.join(GFQRsqliteDB_Path, GFQRsqliteDB_name)

 

        # gdb_name = 'GFQRFileGeodb_{}.gdb'.format(datetime.datetime.now().strftime('%Y%m%d%H%M%S'))  

        # arcpy.CreateFileGDB_management(GFQRsqliteDB_Path, gdb_name)

        # gdb = os.path.join(GFQRsqliteDB_Path, gdb_name)

 

 

        conn = sqlite3.connect(":memory:")

        #conn = sqlite3.connect(GFQRsqliteDB)

        conn.isolation_level = None

        c = conn.cursor()

 

        #Load Nominal->Outside Diameter lookup

        self.Load_Nominal_Diameter_Data(c)

 

        #Copy GasPressureSystem table to memory

        try:

            gps_cols = ["OPSSYSNAME","SYSMOP","SYSMAOP"]

            gps_coltypes = ["TEXT","TEXT","TEXT"]

            self.Copy_To_SQLite_Simple("GasPressureSystem","gaspressuresystem",gps_cols,gps_coltypes,c)

        except:

            raise Exception("GasPressureSystem table is required in ArcMap Table of Contents (TOC) window")

 

        try:

            #Copy GradeYield table to memory

            gy_cols = ["GRADE","YIELD"]

            gy_coltypes = ["TEXT","LONG"]

            self.Copy_To_SQLite_Simple("GradeYield","gradeyield",gy_cols,gy_coltypes,c)       

        except:

            raise Exception("GradeYield table is required in ArcMap Table of Contents (TOC) window")

 

 

 

        #Load boundary layer(s)

        sqlite_types = []

        sqlite_fields = []

        sqlite_aliases = []

        self.Load_Boundary_Layers(p)

 

        #Check if boundary layer(s) have self-intersect inconsistencies

        self.Intersect_Boundaries_Self(p)

 

        #Create pipe and/or point snapshotsexecute

        for i in range(0, len(in_facility_layers)):

 

            in_facility_layers[i] = in_facility_layers[i].replace("'","")

 

            temp_shapetype = self.Get_ShapeType(in_facility_layers[i])

 

            if temp_shapetype == "Polyline":

 

                if pipe_layer_count == 0:

                    self.Create_Pipe_FeatureClass(p)

 

                self.Load_Pipe_Data(p,in_facility_layers[i], c)

                arcpy.AddMessage ("Completed Load_Pipe_Data")

                pipe_layer_count = pipe_layer_count + 1

 

            elif temp_shapetype == "Point":

 

                if point_layer_count == 0:

 

                    #Check if premise snapshot is required

                    if in_point_cols_str.find("PREMISE ID") >= 0 or in_point_cols_str.find("SAP PREMISE ID") >= 0:

                        self.Create_Premise_Snapshot(c)

 

                    self.Create_Point_FeatureClass(p)

 

                self.Load_Point_Data(p, c, in_facility_layers[i])

                point_layer_count = point_layer_count + 1

 

        #Intersect pipes to boundary layer(s)

        if pipe_layer_count > 0:

            pipe_intersect_total = self.Intersect_To_Boundaries(p, "pipes")

 

        #Inersect points to boundary layer(s)

        if point_layer_count > 0:

            point_intersect_total = self.Intersect_Points_To_Boundaries(p, "points")

 

        self.Delete_Boundary_Layers() #Garbage cleanup

 

        ##CGF2 29NOV 2016 -- CRQ000000032190

        ##Optimization to flush each row after a subsequent row is written (frees memory, increases execution speed)

        ##http://xlsxwriter.readthedocs.io/working_with_memory.html#memory-perf

        ##Create Excel workbook

        #workbook = xlsxwriter.Workbook(self.Excel_FilePath(p))

        workbook = xlsxwriter.Workbook(self.Excel_FilePath(p),{'constant_memory': True})

        ##END CGF2

       

        #Check if pipes intersect generated 1 or more records

        if pipe_intersect_total > 0:

 

            #Copy pipe intersect results into SQLite and calculate new recorded lengths

            self.SQLite_Copy_Pipes_Intersect(p,c,"pipes_intersect")           

            if arcpy.Exists("in_memory/pipes_intersect"):

                arcpy.Delete_management("in_memory/pipes_intersect") #Garbage cleanup

 

            #Pipe quanties report worksheet

            self.Pipes_Intersect_To_Excel(p,c,workbook)

 

        #Point quantities report worksheet

        if point_intersect_total > 0:

 

            #Copy point intersect results into SQLite

            self.SQLite_Copy_Points_Intersect(p,c,"points_intersect")

            arcpy.Delete_management("in_memory/points_intersect") #Garbage cleanup

 

            #Point quantities report worksheet

            self.Points_Intersect_To_Excel(p,c,workbook)

 

        #Add boundary self overlap error worksheets

        self.Boundary_Errors_To_Excel(p, workbook, "primary")

        self.Boundary_Errors_To_Excel(p, workbook, "secondary")

 

        #Write query parameters in separate worksheet and close Excel file

        self.Summarize_Workbook(p, workbook)

        workbook.close()

 

        self.Broadcast_Completion_Receipt(p,self.Excel_FilePath(p))

 

        #Garbage cleanup

        arcpy.AddMessage("Cleaning up...")

        c.execute("VACUUM")

        conn.close()

        arcpy.AddMessage("Disconnecting from workspace" + self.Time_Elapsed())

        arcpy.ClearWorkspaceCache_management()

        arcpy.Delete_management("in_memory")

 

        return